{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fab7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fc10b4-77ae-412a-beec-349d6ed9647c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'nvda_news_1.txt'}, page_content=\"The stock of NVIDIA Corp (NASDAQ:NVDA) experienced a daily loss of -3.56% and a 3-month gain of 32.35%. With an Earnings Per Share (EPS) (EPS) of $1.92, the question arises: is the stock significantly overvalued? This article aims to provide a detailed valuation analysis of NVIDIA, offering insights into its financial strength, profitability, growth, and more. We invite you to delve into this comprehensive analysis.\\n\\nCompany Overview\\nWarning! GuruFocus has detected 10 Warning Signs with NVDA. Click here to check it out.\\n\\nNVDA 30-Year Financial Data\\n\\nThe intrinsic value of NVDA\\n\\n\\nNVIDIA Corp (NASDAQ:NVDA) is a leading designer of discrete graphics processing units that enhance the experience on computing platforms. The firm's chips are widely used in various end markets, including PC gaming and data centers. In recent years, NVIDIA has broadened its focus from traditional PC graphics applications such as gaming to more complex and favorable opportunities, including artificial intelligence and autonomous driving, leveraging the high-performance capabilities of its products.\\n\\nCurrently, NVIDIA's stock price stands at $418.01, significantly higher than the GF Value of $310.28, indicating the stock might be overvalued. With a market cap of $1 trillion, the valuation seems steep. The following analysis aims to delve deeper into the company's value.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nUnderstanding the GF Value\\nThe GF Value is a unique measure of the intrinsic value of a stock, calculated based on historical trading multiples, a GuruFocus adjustment factor, and future business performance estimates. If the stock price is significantly above the GF Value Line, it is overvalued, and its future return is likely to be poor. Conversely, if it is significantly below the GF Value Line, its future return will likely be higher.\\n\\nAccording to GuruFocus Value calculation, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. The stock's current price of $418.01 per share and the market cap of $1 trillion further strengthen this assumption.\\n\\nGiven that NVIDIA is significantly overvalued, the long-term return of its stock is likely to be much lower than its future business growth.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nLink: These companies may deliver higher future returns at reduced risk.\\n\\nFinancial Strength of NVIDIA\\nExamining the financial strength of a company is crucial before investing in its stock. Companies with poor financial strength pose a higher risk of permanent loss. NVIDIA's cash-to-debt ratio of 1.27 is worse than 58.04% of companies in the Semiconductors industry. However, NVIDIA's overall financial strength is 8 out of 10, indicating a strong financial position.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nProfitability and Growth\\nConsistent profitability over the long term reduces the risk for investors. NVIDIA, with its profitability ranking of 10 out of 10, has been profitable for the past 10 years. The company's operating margin of 17.37% ranks better than 76.5% of companies in the Semiconductors industry.\\n\\nHowever, growth is a crucial factor in a company's valuation. NVIDIA's growth ranks worse than 52.99% of companies in the Semiconductors industry, with its 3-year average revenue growth rate better than 87.88% of companies in the industry.\\n\\nROIC vs WACC\\nComparing a company's return on invested capital (ROIC) to its weighted average cost of capital (WACC) is an effective way to evaluate its profitability. Over the past 12 months, NVIDIA's ROIC was 20.32 while its WACC was 16.74, suggesting that the company is creating value for its shareholders.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nConclusion\\nIn conclusion, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. Despite its strong financial condition and profitability, its growth ranks lower than 52.99% of companies in the Semiconductors industry. To learn more about NVIDIA stock, you can check out its 30-Year Financials here.\\n\\nTo find out the high quality companies that may deliver above-average returns, please check out GuruFocus High Quality Low Capex Screener.\\n\\nThis article first appeared on GuruFocus.\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"nvda_news_1.txt\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c41716-ab76-4354-abc2-97e37145499f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The stock of NVIDIA Corp (NASDAQ:NVDA) experienced a daily loss of -3.56% and a 3-month gain of 32.35%. With an Earnings Per Share (EPS) (EPS) of $1.92, the question arises: is the stock significantly overvalued? This article aims to provide a detailed valuation analysis of NVIDIA, offering insights into its financial strength, profitability, growth, and more. We invite you to delve into this comprehensive analysis.\\n\\nCompany Overview\\nWarning! GuruFocus has detected 10 Warning Signs with NVDA. Click here to check it out.\\n\\nNVDA 30-Year Financial Data\\n\\nThe intrinsic value of NVDA\\n\\n\\nNVIDIA Corp (NASDAQ:NVDA) is a leading designer of discrete graphics processing units that enhance the experience on computing platforms. The firm's chips are widely used in various end markets, including PC gaming and data centers. In recent years, NVIDIA has broadened its focus from traditional PC graphics applications such as gaming to more complex and favorable opportunities, including artificial intelligence and autonomous driving, leveraging the high-performance capabilities of its products.\\n\\nCurrently, NVIDIA's stock price stands at $418.01, significantly higher than the GF Value of $310.28, indicating the stock might be overvalued. With a market cap of $1 trillion, the valuation seems steep. The following analysis aims to delve deeper into the company's value.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nUnderstanding the GF Value\\nThe GF Value is a unique measure of the intrinsic value of a stock, calculated based on historical trading multiples, a GuruFocus adjustment factor, and future business performance estimates. If the stock price is significantly above the GF Value Line, it is overvalued, and its future return is likely to be poor. Conversely, if it is significantly below the GF Value Line, its future return will likely be higher.\\n\\nAccording to GuruFocus Value calculation, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. The stock's current price of $418.01 per share and the market cap of $1 trillion further strengthen this assumption.\\n\\nGiven that NVIDIA is significantly overvalued, the long-term return of its stock is likely to be much lower than its future business growth.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nLink: These companies may deliver higher future returns at reduced risk.\\n\\nFinancial Strength of NVIDIA\\nExamining the financial strength of a company is crucial before investing in its stock. Companies with poor financial strength pose a higher risk of permanent loss. NVIDIA's cash-to-debt ratio of 1.27 is worse than 58.04% of companies in the Semiconductors industry. However, NVIDIA's overall financial strength is 8 out of 10, indicating a strong financial position.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nProfitability and Growth\\nConsistent profitability over the long term reduces the risk for investors. NVIDIA, with its profitability ranking of 10 out of 10, has been profitable for the past 10 years. The company's operating margin of 17.37% ranks better than 76.5% of companies in the Semiconductors industry.\\n\\nHowever, growth is a crucial factor in a company's valuation. NVIDIA's growth ranks worse than 52.99% of companies in the Semiconductors industry, with its 3-year average revenue growth rate better than 87.88% of companies in the industry.\\n\\nROIC vs WACC\\nComparing a company's return on invested capital (ROIC) to its weighted average cost of capital (WACC) is an effective way to evaluate its profitability. Over the past 12 months, NVIDIA's ROIC was 20.32 while its WACC was 16.74, suggesting that the company is creating value for its shareholders.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nConclusion\\nIn conclusion, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. Despite its strong financial condition and profitability, its growth ranks lower than 52.99% of companies in the Semiconductors industry. To learn more about NVIDIA stock, you can check out its 30-Year Financials here.\\n\\nTo find out the high quality companies that may deliver above-average returns, please check out GuruFocus High Quality Low Capex Screener.\\n\\nThis article first appeared on GuruFocus.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d628b1ec-b5a2-4c33-ae02-61c97fb8ac21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'nvda_news_1.txt'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f06c20e-d486-4be4-9a56-7c52e12a7264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\"movies.csv\")\n",
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4229dd68-4740-4465-8024-fa09c9f97918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed6c6458-f03f-4f49-a91d-42df6a412f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'movies.csv', 'row': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4efdfb9-9ebc-4ccf-9156-5df78887007a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'movies.csv', 'row': 0}, page_content='movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 1}, page_content='movie_id: 102\\ntitle: Doctor Strange in the Multiverse of Madness\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 7\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 200\\nrevenue: 954.8\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 2}, page_content='movie_id: 103\\ntitle: Thor: The Dark World\\nindustry: Hollywood\\nrelease_year: 2013\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 165\\nrevenue: 644.8\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 3}, page_content='movie_id: 104\\ntitle: Thor: Ragnarok\\nindustry: Hollywood\\nrelease_year: 2017\\nimdb_rating: 7.9\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 180\\nrevenue: 854\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 4}, page_content='movie_id: 105\\ntitle: Thor: Love and Thunder\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 250\\nrevenue: 670\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 5}, page_content='movie_id: 106\\ntitle: Sholay\\nindustry: Bollywood\\nrelease_year: 1975\\nimdb_rating: 8.1\\nstudio: United Producers\\nlanguage_id: 1\\nbudget: Not Available\\nrevenue: Not Available\\nunit: Not Available\\ncurrency: Not Available'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 6}, page_content='movie_id: 107\\ntitle: Dilwale Dulhania Le Jayenge\\nindustry: Bollywood\\nrelease_year: 1995\\nimdb_rating: 8\\nstudio: Yash Raj Films\\nlanguage_id: 1\\nbudget: 400\\nrevenue: 2000\\nunit: Millions\\ncurrency: INR'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 7}, page_content='movie_id: 108\\ntitle: 3 Idiots\\nindustry: Bollywood\\nrelease_year: 2009\\nimdb_rating: 8.4\\nstudio: Vinod Chopra Films\\nlanguage_id: 1\\nbudget: 550\\nrevenue: 4000\\nunit: Millions\\ncurrency: INR'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 8}, page_content='movie_id: 109\\ntitle: Kabhi Khushi Kabhie Gham\\nindustry: Bollywood\\nrelease_year: 2001\\nimdb_rating: 7.4\\nstudio: Dharma Productions\\nlanguage_id: 1\\nbudget: 390\\nrevenue: 1360\\nunit: Millions\\ncurrency: INR')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf8a2825-fb56-440d-ac46-2e615dfd3acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in ./.venv/lib/python3.11/site-packages (0.18.11)\n",
      "Requirement already satisfied: libmagic in ./.venv/lib/python3.11/site-packages (1.0)\n",
      "Requirement already satisfied: python-magic in ./.venv/lib/python3.11/site-packages (0.4.27)\n",
      "Requirement already satisfied: python-magic-bin in ./.venv/lib/python3.11/site-packages (0.4.14)\n",
      "Requirement already satisfied: charset-normalizer in ./.venv/lib/python3.11/site-packages (from unstructured) (3.4.3)\n",
      "Requirement already satisfied: filetype in ./.venv/lib/python3.11/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.11/site-packages (from unstructured) (6.0.0)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.11/site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from unstructured) (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.11/site-packages (from unstructured) (4.13.4)\n",
      "Requirement already satisfied: emoji in ./.venv/lib/python3.11/site-packages (from unstructured) (2.14.1)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.11/site-packages (from unstructured) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in ./.venv/lib/python3.11/site-packages (from unstructured) (2025.2.18)\n",
      "Requirement already satisfied: langdetect in ./.venv/lib/python3.11/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from unstructured) (2.3.2)\n",
      "Requirement already satisfied: rapidfuzz in ./.venv/lib/python3.11/site-packages (from unstructured) (3.13.0)\n",
      "Requirement already satisfied: backoff in ./.venv/lib/python3.11/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.11/site-packages (from unstructured) (4.14.1)\n",
      "Requirement already satisfied: unstructured-client in ./.venv/lib/python3.11/site-packages (from unstructured) (0.42.2)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.11/site-packages (from unstructured) (1.17.2)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from unstructured) (7.0.0)\n",
      "Requirement already satisfied: python-oxmsg in ./.venv/lib/python3.11/site-packages (from unstructured) (0.0.2)\n",
      "Requirement already satisfied: html5lib in ./.venv/lib/python3.11/site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.11/site-packages (from beautifulsoup4->unstructured) (2.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (25.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9 in ./.venv/lib/python3.11/site-packages (from html5lib->unstructured) (1.17.0)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.11/site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk->unstructured) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk->unstructured) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk->unstructured) (2025.7.34)\n",
      "Requirement already satisfied: olefile in ./.venv/lib/python3.11/site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->unstructured) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->unstructured) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->unstructured) (2025.8.3)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured) (45.0.6)\n",
      "Requirement already satisfied: httpcore>=1.0.9 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured) (1.0.9)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.11.2 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured) (2.11.7)\n",
      "Requirement already satisfied: pypdf>=4.0 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured) (5.9.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.14 in ./.venv/lib/python3.11/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore>=1.0.9->unstructured-client->unstructured) (0.16.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install unstructured libmagic python-magic python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ebe603d-a78a-468c-84a8-bc75736dff43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'movies.csv', 'row': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2780b97-1fd1-4179-8a18-a47619139baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\"movies.csv\", source_column=\"title\")\n",
    "data = loader.load()\n",
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9854c86-e9f5-415a-b96c-7174488e796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8823b79-75b9-483f-8022-46360fab0cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=[\n",
    "    \"https://www.bbc.com/news/articles/c51y0p1m1w4o\",  # BBC News article\n",
    "    \"https://www.reuters.com/technology/apple-reports-quarterly-results-2025-08-08/\"  # Reuters tech news\n",
    "])\n",
    "\n",
    "data = loader.load()\n",
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49170bf1-9fca-48b3-a94a-c59131b608ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87c5a5ea-7106-42f4-8b52-67c3a0c48bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.bbc.com/news/articles/c51y0p1m1w4o'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "191f4bea-e1fd-4043-acd1-cbeb9d89b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking some random text from wikipedia\n",
    "\n",
    "text = \"\"\"Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. \n",
    "It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine. \n",
    "Set in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts \n",
    "who travel through a wormhole near Saturn in search of a new home for humankind.\n",
    "\n",
    "Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007 and was \n",
    "based on the works of theoretical physicist Kip Thorne, a Caltech theoretical physicist and 2017 Nobel laureate in Physics,[4] was an executive producer, acted as a scientific consultant, \n",
    "and wrote the tie-in book The Science of Interstellar. Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm. \n",
    "Principal photography began in late 2013 and took place in Alberta, Canada, and Iceland. Interstellar uses extensive practical and miniature effects, and the company Double Negative created additional digital effects.\n",
    "\n",
    "Interstellar premiered in Los Angeles on October 26, 2014. In the United States, it was first released on film stock formats before expanding to venues with digital projectors. \n",
    "It has been praised by astronomers for its scientific accuracy and portrayal of theoretical astrophysics.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd2438f7-ec80-4f43-96c6-b563170cc064",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2308afdd-ff70-4dc4-9cd1-cc132b177f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "s = \"\"\n",
    "for word in words:\n",
    "    s += word + \" \"\n",
    "    if len(s) > 200:\n",
    "        chunks.append(s.strip())\n",
    "        s = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35915682-b0ba-4418-aa2e-28fd0a3e95f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt',\n",
       " 'Damon, and Michael Caine. Set in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in',\n",
       " 'search of a new home for humankind. Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007 and was based on the works of theoretical',\n",
       " 'physicist Kip Thorne, a Caltech theoretical physicist and 2017 Nobel laureate in Physics,[4] was an executive producer, acted as a scientific consultant, and wrote the tie-in book The Science of Interstellar.',\n",
       " 'Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm. Principal photography began in late 2013 and took place in Alberta, Canada, and Iceland.',\n",
       " 'Interstellar uses extensive practical and miniature effects, and the company Double Negative created additional digital effects. Interstellar premiered in Los Angeles on October 26, 2014. In the United',\n",
       " 'States, it was first released on film stock formats before expanding to venues with digital projectors. It has been praised by astronomers for its scientific accuracy and portrayal of theoretical astrophysics.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46c20953-ed55-4e05-8af6-a779cc202c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 217, which is longer than the specified 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)\n",
    "len(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbb3f536-afaf-4c36-bcf5-93203a4c7534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan.',\n",
       " 'It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine.',\n",
       " 'Set in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts',\n",
       " 'who travel through a wormhole near Saturn in search of a new home for humankind.',\n",
       " 'Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007 and was',\n",
       " 'based on the works of theoretical physicist Kip Thorne, a Caltech theoretical physicist and 2017 Nobel laureate in Physics,[4] was an executive producer, acted as a scientific consultant,',\n",
       " 'and wrote the tie-in book The Science of Interstellar. Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm.',\n",
       " 'Principal photography began in late 2013 and took place in Alberta, Canada, and Iceland. Interstellar uses extensive practical and miniature effects, and the company Double Negative created additional digital effects.',\n",
       " 'Interstellar premiered in Los Angeles on October 26, 2014. In the United States, it was first released on film stock formats before expanding to venues with digital projectors.',\n",
       " 'It has been praised by astronomers for its scientific accuracy and portrayal of theoretical astrophysics.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1946dda0-b0be-44bc-9a08-2764f2d38bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "120\n",
      "129\n",
      "80\n",
      "130\n",
      "187\n",
      "168\n",
      "217\n",
      "176\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(len(chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e4b464f-57c8-4953-ae49-efdedb7b8728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \"],\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "chunks = r_splitter.split_text(text)\n",
    "len(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16cc47a8-b974-470d-9af9-c3f42f9c5e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "120\n",
      "129\n",
      "80\n",
      "130\n",
      "187\n",
      "168\n",
      "189\n",
      "27\n",
      "176\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(len(chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08a4f1d7-b73c-4534-856a-c5d0e8e7d247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "708\n",
      "283\n"
     ]
    }
   ],
   "source": [
    "chunks = text.split(\"\\n\\n\")\n",
    "for chunk in chunks:\n",
    "    print(len(chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b991aab-db94-46c2-809f-27476f3a2688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. \\nIt stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine. \\nSet in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts \\nwho travel through a wormhole near Saturn in search of a new home for humankind.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_split = chunks[0]\n",
    "first_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac31037f-fd83-4f0b-bf3c-de590febfe50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Set',\n",
       " 'in',\n",
       " 'a',\n",
       " 'dystopian',\n",
       " 'future',\n",
       " 'where',\n",
       " 'humanity',\n",
       " 'is',\n",
       " 'embroiled',\n",
       " 'in',\n",
       " 'a',\n",
       " 'catastrophic',\n",
       " 'blight',\n",
       " 'and',\n",
       " 'famine,',\n",
       " 'the',\n",
       " 'film',\n",
       " 'follows',\n",
       " 'a',\n",
       " 'group',\n",
       " 'of',\n",
       " 'astronauts',\n",
       " '']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_split = first_split.split(\"\\n\")\n",
    "\n",
    "second_split[2].split(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2eb0da5f-d6c7-48de-9f60-5a0f12e635b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0.post1-cp311-cp311-macosx_13_0_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./.venv/lib/python3.11/site-packages (from faiss-cpu) (2.3.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from faiss-cpu) (25.0)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.1-cp311-cp311-macosx_14_0_x86_64.whl.metadata (61 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.3.0-cp311-cp311-macosx_10_10_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.14.1)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.1.7-cp37-abi3-macosx_10_12_x86_64.whl.metadata (703 bytes)\n",
      "Collecting sympy (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading faiss_cpu-1.11.0.post1-cp311-cp311-macosx_13_0_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Downloading transformers-4.55.0-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.7-cp37-abi3-macosx_10_12_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-macosx_10_12_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-macosx_10_12_x86_64.whl (454 kB)\n",
      "Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m  \u001b[33m0:00:14\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.3.0-cp311-cp311-macosx_10_10_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.1-cp311-cp311-macosx_10_9_x86_64.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading scipy-1.16.1-cp311-cp311-macosx_14_0_x86_64.whl (23.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, threadpoolctl, sympy, scipy, safetensors, Pillow, networkx, hf-xet, fsspec, filelock, faiss-cpu, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Pillow-11.3.0 faiss-cpu-1.11.0.post1 filelock-3.18.0 fsspec-2025.7.0 hf-xet-1.1.7 huggingface-hub-0.34.4 mpmath-1.3.0 networkx-3.5 safetensors-0.6.2 scikit-learn-1.7.1 scipy-1.16.1 sentence-transformers-5.1.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.21.4 torch-2.2.2 transformers-4.55.0\n"
     ]
    }
   ],
   "source": [
    "# Install (run in a new cell)\n",
    "!pip install -U faiss-cpu sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c67a0483-c82d-4ea1-a96c-3bfa4a93faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2057cc80-e5b2-4ac4-bfcc-2596892ad2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bdfae33-face-4a84-8aa7-884b838eee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75d86d54-e48a-4ffe-a5f2-3563965b77b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b979a9b-5510-47db-a5e3-1cb0869605c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meditation and yoga can improve mental health</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fruits, whole grains and vegetables helps control blood pressure</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These are the latest fashion trends for this week</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vibrant color jeans for male are becoming a trend</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The concert starts at 7 PM tonight</td>\n",
       "      <td>Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Navaratri dandiya program at Expo center in Mumbai this october</td>\n",
       "      <td>Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Exciting vacation destinations for your next trip</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maldives and Srilanka are gaining popularity in terms of low budget vacation places</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  text  \\\n",
       "0                                        Meditation and yoga can improve mental health   \n",
       "1                     Fruits, whole grains and vegetables helps control blood pressure   \n",
       "2                                    These are the latest fashion trends for this week   \n",
       "3                                    Vibrant color jeans for male are becoming a trend   \n",
       "4                                                   The concert starts at 7 PM tonight   \n",
       "5                      Navaratri dandiya program at Expo center in Mumbai this october   \n",
       "6                                    Exciting vacation destinations for your next trip   \n",
       "7  Maldives and Srilanka are gaining popularity in terms of low budget vacation places   \n",
       "\n",
       "  category  \n",
       "0   Health  \n",
       "1   Health  \n",
       "2  Fashion  \n",
       "3  Fashion  \n",
       "4    Event  \n",
       "5    Event  \n",
       "6   Travel  \n",
       "7   Travel  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea7b3151-acb7-4165-9c94-4eb7f58cb599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.11/site-packages (5.1.0)\n",
      "Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.11/site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.55.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f1bcc7-240c-410c-b0de-3ea24f9b9e4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      3\u001b[39m encoder = SentenceTransformer(\u001b[33m\"\u001b[39m\u001b[33mall-mpnet-base-v2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m vectors = encoder.encode(\u001b[43mdf\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).tolist())\n\u001b[32m      5\u001b[39m vectors.shape\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "vectors = encoder.encode(df[\"text\"].astype(str).tolist())\n",
    "vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ecdda03-6888-44e3-84d4-6a58934826d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.3.2\n",
      "Uninstalling numpy-2.3.2:\n",
      "  Successfully uninstalled numpy-2.3.2\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.2-cp311-cp311-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Using cached numpy-2.3.2-cp311-cp311-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e544829-dce1-46c2-a5a6-71bf06640629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/fariskajani/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/fariskajani/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/fariskajani/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/sn/z9rqrx2562d9qq96khj5vjrc0000gn/T/ipykernel_8621/2926875944.py\", line 1, in <module>\n",
      "    from sentence_transformers import SentenceTransformer\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/sentence_transformers/__init__.py\", line 10, in <module>\n",
      "    from sentence_transformers.backend import (\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/sentence_transformers/backend/__init__.py\", line 3, in <module>\n",
      "    from .load import load_onnx_model, load_openvino_model\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/sentence_transformers/backend/load.py\", line 7, in <module>\n",
      "    from transformers.configuration_utils import PretrainedConfig\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/transformers/__init__.py\", line 27, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/transformers/utils/__init__.py\", line 24, in <module>\n",
      "    from .auto_docstring import (\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/transformers/utils/auto_docstring.py\", line 30, in <module>\n",
      "    from .generic import ModelOutput\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/transformers/utils/generic.py\", line 53, in <module>\n",
      "    import torch  # noqa: F401\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      3\u001b[39m encoder = SentenceTransformer(\u001b[33m\"\u001b[39m\u001b[33mall-mpnet-base-v2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m vectors = encoder.encode(\u001b[43mdf\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).tolist())\n\u001b[32m      5\u001b[39m vectors.shape\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "vectors = encoder.encode(df[\"text\"].astype(str).tolist())\n",
    "vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "848ea591-a1bd-4e51-a76e-a3fb8882bf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: torch==2.2.2 in ./.venv/lib/python3.11/site-packages (2.2.2)\n",
      "Collecting sentence-transformers==2.5.1\n",
      "  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting faiss-cpu==1.7.4\n",
      "  Downloading faiss_cpu-1.7.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (4.14.1)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (2025.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (4.55.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (1.7.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (0.34.4)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (11.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (2025.7.34)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (0.6.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (1.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.11/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.11/site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch==2.2.2) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers==2.5.1) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers==2.5.1) (3.6.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Downloading numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
      "Downloading faiss_cpu-1.7.4-cp311-cp311-macosx_10_9_x86_64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu, widgetsnbextension, numpy, jupyterlab_widgets, ipywidgets, sentence-transformers\n",
      "\u001b[2K  Attempting uninstall: faiss-cpu\n",
      "\u001b[2K    Found existing installation: faiss-cpu 1.11.0.post1\n",
      "\u001b[2K    Uninstalling faiss-cpu-1.11.0.post1:\n",
      "\u001b[2K      Successfully uninstalled faiss-cpu-1.11.0.post1\n",
      "\u001b[2K  Attempting uninstall: numpy━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/6\u001b[0m [faiss-cpu]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.2\u001b[0m \u001b[32m0/6\u001b[0m [faiss-cpu]\n",
      "\u001b[2K    Uninstalling numpy-2.3.2:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.2━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: sentence-transformers[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [ipywidgets]\n",
      "\u001b[2K    Found existing installation: sentence-transformers 5.1.0━━\u001b[0m \u001b[32m4/6\u001b[0m [ipywidgets]\n",
      "\u001b[2K    Uninstalling sentence-transformers-5.1.0:[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [ipywidgets]\n",
      "\u001b[2K      Successfully uninstalled sentence-transformers-5.1.0━━━━\u001b[0m \u001b[32m4/6\u001b[0m [ipywidgets]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed faiss-cpu-1.7.4 ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 numpy-1.26.4 sentence-transformers-2.5.1 widgetsnbextension-4.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"numpy==1.26.4\" \"torch==2.2.2\" \"sentence-transformers==2.5.1\" \"faiss-cpu==1.7.4\" ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578227e5-eda4-4be4-b6c3-2c9fc4965bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed209b1-1d18-46b0-999c-dcf2867b2b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 2),\n",
       "                                                                text category\n",
       " 0                     Meditation and yoga can improve mental health   Health\n",
       " 1  Fruits, whole grains and vegetables helps control blood pressure   Health)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "df = pd.read_csv(\"sample_text.csv\")  # make sure this file is in the same folder as the notebook\n",
    "df.shape, df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c907a9ee-9c10-4edf-be7b-7288f390365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████| 1/1 [00:07<00:00,  7.52s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m encoder = SentenceTransformer(\u001b[33m\"\u001b[39m\u001b[33msentence-transformers/all-mpnet-base-v2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m texts = df[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).tolist()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m vectors = \u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m vectors.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/genai-finance/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/genai-finance/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1109\u001b[39m, in \u001b[36mencode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prompts:\n\u001b[32m   1108\u001b[39m         \u001b[38;5;28mself\u001b[39m.prompts = \u001b[38;5;28mself\u001b[39m._model_config.get(\u001b[33m\"\u001b[39m\u001b[33mprompts\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m-> \u001b[39m\u001b[32m1109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_prompt_name:\n\u001b[32m   1110\u001b[39m         \u001b[38;5;28mself\u001b[39m.default_prompt_name = \u001b[38;5;28mself\u001b[39m._model_config.get(\u001b[33m\"\u001b[39m\u001b[33mdefault_prompt_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1112\u001b[39m \u001b[38;5;66;03m# Check if a readme exists\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/genai-finance/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1109\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prompts:\n\u001b[32m   1108\u001b[39m         \u001b[38;5;28mself\u001b[39m.prompts = \u001b[38;5;28mself\u001b[39m._model_config.get(\u001b[33m\"\u001b[39m\u001b[33mprompts\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m-> \u001b[39m\u001b[32m1109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_prompt_name:\n\u001b[32m   1110\u001b[39m         \u001b[38;5;28mself\u001b[39m.default_prompt_name = \u001b[38;5;28mself\u001b[39m._model_config.get(\u001b[33m\"\u001b[39m\u001b[33mdefault_prompt_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1112\u001b[39m \u001b[38;5;66;03m# Check if a readme exists\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "texts = df[\"text\"].astype(str).tolist()\n",
    "\n",
    "vectors = encoder.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db06de0a-aa7f-4475-af31-3483102f11dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/z9rqrx2562d9qq96khj5vjrc0000gn/T/ipykernel_8621/845848258.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[32m      4\u001b[39m emb = HuggingFaceEmbeddings(model_name=\u001b[33m\"\u001b[39m\u001b[33msentence-transformers/all-mpnet-base-v2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m vs = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m vs.similarity_search(\u001b[33m\"\u001b[39m\u001b[33mmental health\u001b[39m\u001b[33m\"\u001b[39m, k=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/genai-finance/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/genai-finance/.venv/lib/python3.11/site-packages/langchain_community/embeddings/huggingface.py:115\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    113\u001b[39m     sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings.tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/genai-finance/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/genai-finance/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1109\u001b[39m, in \u001b[36mencode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prompts:\n\u001b[32m   1108\u001b[39m         \u001b[38;5;28mself\u001b[39m.prompts = \u001b[38;5;28mself\u001b[39m._model_config.get(\u001b[33m\"\u001b[39m\u001b[33mprompts\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m-> \u001b[39m\u001b[32m1109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_prompt_name:\n\u001b[32m   1110\u001b[39m         \u001b[38;5;28mself\u001b[39m.default_prompt_name = \u001b[38;5;28mself\u001b[39m._model_config.get(\u001b[33m\"\u001b[39m\u001b[33mdefault_prompt_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1112\u001b[39m \u001b[38;5;66;03m# Check if a readme exists\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/genai-finance/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1109\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prompts:\n\u001b[32m   1108\u001b[39m         \u001b[38;5;28mself\u001b[39m.prompts = \u001b[38;5;28mself\u001b[39m._model_config.get(\u001b[33m\"\u001b[39m\u001b[33mprompts\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m-> \u001b[39m\u001b[32m1109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_prompt_name:\n\u001b[32m   1110\u001b[39m         \u001b[38;5;28mself\u001b[39m.default_prompt_name = \u001b[38;5;28mself\u001b[39m._model_config.get(\u001b[33m\"\u001b[39m\u001b[33mdefault_prompt_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1112\u001b[39m \u001b[38;5;66;03m# Check if a readme exists\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "vs = FAISS.from_texts(texts, embedding=emb)\n",
    "vs.similarity_search(\"mental health\", k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cca0587-4c0b-4c32-85e5-a43685807fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.26.4\n",
      "Uninstalling numpy-1.26.4:\n",
      "  Successfully uninstalled numpy-1.26.4\n",
      "Found existing installation: torch 2.2.2\n",
      "Uninstalling torch-2.2.2:\n",
      "  Successfully uninstalled torch-2.2.2\n",
      "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Installing collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 2.5.1 requires torch>=1.11.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch==2.2.2\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (151.0 MB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (4.14.1)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch==2.2.2) (2025.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch==2.2.2) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.2.2\n",
      "Requirement already satisfied: sentence-transformers==2.5.1 in ./.venv/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: faiss-cpu==1.7.4 in ./.venv/lib/python3.11/site-packages (1.7.4)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.11/site-packages (8.1.7)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (4.55.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (2.2.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (1.7.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (0.34.4)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (from sentence-transformers==2.5.1) (11.3.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (2025.7.34)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (1.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.11/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.11/site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.venv/lib/python3.11/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.11/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.5.1) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers==2.5.1) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers==2.5.1) (3.6.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers==2.5.1) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy torch torchvision torchaudio\n",
    "!pip install \"numpy==1.26.4\"\n",
    "!pip install \"torch==2.2.2\" --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install \"sentence-transformers==2.5.1\" \"faiss-cpu==1.7.4\" ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074cb17f-edfa-49cf-8261-aba961a70d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.26.4\n",
      "torch: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import numpy, torch\n",
    "print(\"numpy:\", numpy.__version__)\n",
    "print(\"torch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e34a8b76-97f7-4abc-8e23-eb5eda8c48fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 2),\n",
       "                                                                text category\n",
       " 0                     Meditation and yoga can improve mental health   Health\n",
       " 1  Fruits, whole grains and vegetables helps control blood pressure   Health)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "df = pd.read_csv(\"sample_text.csv\")\n",
    "df.shape, df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e39133a-dbe6-4fb1-9933-16c25bccd0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173a547ff03d4b84b1fe1345b3a6dd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8, 768)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "texts = df[\"text\"].astype(str).tolist()\n",
    "\n",
    "vectors = encoder.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12393e0a-bfcc-42fc-a510-ce1e96aed83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00247388,  0.03626731, -0.05290459, ..., -0.09152354,\n",
       "        -0.03970003, -0.04330491],\n",
       "       [-0.03357265,  0.00980515, -0.03250126, ..., -0.05165475,\n",
       "         0.02245889, -0.03156182],\n",
       "       [-0.0186533 , -0.04051305, -0.01235388, ...,  0.00610588,\n",
       "        -0.07179645,  0.02773849],\n",
       "       ...,\n",
       "       [-0.00066457,  0.04252125, -0.05645504, ...,  0.01315468,\n",
       "        -0.03183559, -0.04357664],\n",
       "       [-0.03317153,  0.03252462, -0.02484841, ...,  0.01174416,\n",
       "         0.0574712 ,  0.00571026],\n",
       "       [-0.00166395,  0.00413833, -0.0459708 , ...,  0.02008534,\n",
       "         0.05656246, -0.00161595]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "461ae665-73d6-44b9-88ea-5354524caba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = vectors.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd3dc617-add7-4d84-b7f9-7672bdfc4e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x184f83840> >"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(dim)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d51e09aa-1196-4af3-949b-59d03cd7eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "781206f5-b29e-4916-8730-aaec3ad3bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"I want to buy a polo t-shirt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0c79241-0568-48a1-8b0d-5389cb297e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = encoder.encode(search_query)\n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd8d3a5e-7849-4ad2-9ce8-d814be20631a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "svec = np.array(vec).reshape(1, -1)\n",
    "svec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "237d5c7d-9fee-41ab-a335-1d0eac018c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.3844838, 1.4039097, 1.7325616]], dtype=float32), array([[3, 2, 5]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(svec, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aebde4cb-4a01-42f2-9eda-bded1efbcd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.03882700e-02,  2.78685484e-02, -1.18618105e-02,  1.81327220e-02,\n",
       "        1.21982570e-03, -1.42995454e-02,  1.96229313e-02,  2.07197927e-02,\n",
       "       -2.23660693e-02,  4.75626662e-02,  1.77976135e-02, -8.00332427e-03,\n",
       "        2.53419187e-02,  5.26148640e-02,  8.44945665e-03, -1.63943768e-02,\n",
       "        1.02661066e-02, -2.74856482e-02,  8.37067068e-02, -1.52885355e-02,\n",
       "        1.67682376e-02, -3.97137273e-03, -2.74349079e-02,  5.02092130e-02,\n",
       "       -8.36520549e-03, -4.74075153e-02,  2.36915890e-02, -1.01186074e-02,\n",
       "       -2.82840580e-02,  7.94267375e-03,  4.21435460e-02, -4.19378374e-03,\n",
       "       -1.91232879e-02, -3.12785544e-02,  1.24685084e-06, -1.04428530e-02,\n",
       "       -2.19971761e-02, -8.66928175e-02, -1.88501901e-03, -2.54772026e-02,\n",
       "       -9.72971227e-03,  7.93310255e-02, -3.55962925e-02, -3.05342750e-04,\n",
       "       -1.12392586e-02, -3.88931967e-02,  5.49314395e-02,  1.35208026e-01,\n",
       "       -8.19147602e-02,  1.18784951e-02, -9.01846774e-03,  1.92544367e-02,\n",
       "       -2.82723829e-02, -3.29267196e-02, -2.20107492e-02, -4.29836139e-02,\n",
       "        3.70104499e-02, -4.80648950e-02,  9.49249044e-03,  3.51585485e-02,\n",
       "        4.88772281e-02, -3.28932740e-02, -1.24120079e-02, -1.64292622e-02,\n",
       "        3.93721424e-02,  2.69109644e-02,  6.15458488e-02, -4.14122455e-03,\n",
       "        1.75675172e-02,  1.53993601e-02,  9.60063841e-03, -5.69581054e-04,\n",
       "       -4.83582616e-02,  4.25831787e-02,  1.10985609e-02, -4.66182567e-02,\n",
       "       -2.10591918e-03, -5.81461824e-02,  1.40412860e-02,  1.00883739e-02,\n",
       "       -2.44590119e-02,  1.42714791e-02, -2.10581906e-02,  7.38854259e-02,\n",
       "       -2.23950054e-02,  1.38753178e-02, -1.33593439e-03,  9.21319053e-03,\n",
       "       -2.84222253e-02, -4.04208759e-03, -1.71393137e-02, -8.46527983e-03,\n",
       "       -2.83983871e-02, -3.69299874e-02, -9.47201177e-02, -3.26580442e-02,\n",
       "        2.60050166e-02,  1.31178899e-02,  1.51670696e-02, -2.12381291e-03,\n",
       "        1.48177920e-02,  1.37817087e-02,  1.25303064e-02, -5.01471339e-03,\n",
       "        3.56062278e-02,  5.93454354e-02, -5.03398143e-02, -9.55990795e-03,\n",
       "       -7.23669231e-02,  9.45842639e-03,  1.54202767e-02, -7.03745335e-03,\n",
       "       -3.10014226e-02, -8.86358693e-03, -2.98000928e-02, -8.84007812e-02,\n",
       "       -2.25059129e-02, -3.25824358e-02,  4.78070043e-02,  2.14020722e-03,\n",
       "        1.37761864e-03, -1.25065912e-02, -1.15712341e-02,  2.34021675e-02,\n",
       "        3.43836239e-03,  2.69363150e-02, -6.23307154e-02, -5.29250037e-03,\n",
       "        1.73164241e-03,  3.20438966e-02,  2.13047402e-04, -1.54123809e-02,\n",
       "        5.08342907e-02, -4.52312939e-02, -1.67427827e-02, -3.47918086e-02,\n",
       "       -4.16715518e-02, -2.34929398e-02,  2.40796595e-03, -2.15250645e-02,\n",
       "        3.07007483e-03,  2.54971068e-02,  3.60133648e-02,  2.68477760e-02,\n",
       "       -4.22385745e-02, -2.45388784e-02,  3.93798761e-02,  6.31313445e-03,\n",
       "        2.03843545e-02, -2.22934633e-02, -7.87332747e-03, -1.47401225e-02,\n",
       "        4.87235375e-02, -2.55933180e-02, -1.08920811e-02, -3.37023064e-02,\n",
       "        4.69094962e-02,  1.95820946e-02,  4.13415115e-03,  2.72842813e-02,\n",
       "        4.72923712e-04,  2.55069938e-02, -5.26176244e-02,  3.57674882e-02,\n",
       "       -5.46486583e-03, -3.90751287e-02, -4.51455973e-02, -1.37631288e-02,\n",
       "        5.50721101e-02,  3.80344018e-02, -4.58983816e-02,  4.83396463e-03,\n",
       "       -2.92574242e-02, -4.76552360e-03,  9.17753503e-02, -9.70399827e-02,\n",
       "        1.05631799e-01, -5.64411655e-02, -6.33300170e-02,  3.45335230e-02,\n",
       "       -5.77132925e-02, -1.21777318e-01,  9.45339818e-03,  2.02731118e-02,\n",
       "        2.63032094e-02,  3.96900298e-03, -3.88275348e-02, -1.57009419e-02,\n",
       "       -3.47952209e-02, -3.07987947e-02,  3.24619897e-02, -4.84479815e-02,\n",
       "        4.39476641e-03, -1.72206610e-02,  1.15584167e-04, -3.72782163e-02,\n",
       "       -5.17302640e-02, -1.91914961e-02, -3.10722739e-02,  4.77238325e-03,\n",
       "       -5.49007133e-02, -1.40049309e-02,  2.99300998e-02,  9.23176780e-02,\n",
       "       -2.96304077e-02,  2.45515388e-02,  3.50713581e-02, -5.64088020e-03,\n",
       "        1.57490168e-02,  2.08431743e-02,  5.11531830e-02,  7.25738937e-03,\n",
       "        4.40726662e-03, -2.58071963e-02,  4.99892468e-03, -1.47745281e-03,\n",
       "       -4.42324718e-03,  4.48388569e-02,  7.79227838e-02,  1.65748112e-02,\n",
       "       -3.80822457e-02,  3.76827866e-02,  1.02415621e-01, -1.61058474e-02,\n",
       "        7.32477158e-02, -1.11488895e-02,  3.81630063e-02,  2.02278346e-02,\n",
       "       -1.23596732e-02,  2.38338336e-02, -2.99291667e-02, -7.08034076e-03,\n",
       "        1.23009877e-02, -6.69539114e-03, -6.65793791e-02,  6.94696307e-02,\n",
       "        1.02031408e-02, -2.23912131e-02, -1.79656334e-02, -3.10914274e-02,\n",
       "       -3.04419678e-02, -2.43376065e-02,  2.62913052e-02, -1.44890565e-02,\n",
       "       -3.44527364e-02,  3.69897671e-03,  2.34961864e-02, -2.20465679e-02,\n",
       "       -6.40620217e-02, -3.29653583e-02, -1.13152880e-02,  4.46261466e-02,\n",
       "        2.82178354e-02, -1.32326260e-02, -2.48316675e-02, -4.16194461e-02,\n",
       "       -3.17105167e-02, -2.90316530e-03, -2.58373823e-02, -2.38407478e-02,\n",
       "        4.09952924e-02, -3.72038931e-02,  3.80427018e-02,  2.60184668e-02,\n",
       "        3.78452502e-02, -1.22929495e-02, -1.78747308e-02,  2.22684685e-02,\n",
       "       -1.39293233e-02,  3.33376718e-03, -1.01043740e-02, -9.42678899e-02,\n",
       "        2.93327589e-02, -2.11533997e-02, -8.28083977e-03,  9.39183310e-03,\n",
       "        7.01194480e-02, -2.47647930e-02, -7.45412335e-03,  1.81595180e-02,\n",
       "        2.10113544e-02,  5.30431904e-02, -1.83114279e-02,  2.45678052e-02,\n",
       "        1.81325637e-02, -1.36736697e-02, -2.25669960e-03,  2.27259938e-02,\n",
       "       -1.32561419e-02,  5.31734191e-02,  2.84625031e-03, -1.26052834e-02,\n",
       "        5.37055321e-02, -2.62218323e-02,  6.28261864e-02, -3.38792503e-02,\n",
       "        1.24345170e-02,  3.83227295e-03,  2.31523160e-02, -7.25013539e-02,\n",
       "       -4.14387556e-03, -4.29395810e-02, -9.25691426e-03, -1.02920374e-02,\n",
       "       -2.94399858e-02, -1.51161207e-02,  1.03488723e-02, -8.83047283e-03,\n",
       "        7.79084396e-03,  6.15880452e-02, -2.56217867e-02,  2.67890971e-02,\n",
       "       -3.48655246e-02, -3.35103758e-02,  4.58869301e-02,  2.87142601e-02,\n",
       "       -1.73843671e-02,  9.46802273e-02, -2.42618341e-02,  2.83706915e-02,\n",
       "        5.47288777e-03, -3.05395722e-02, -2.04882082e-02,  1.14950901e-02,\n",
       "       -2.06157099e-02, -4.73046526e-02, -5.66288829e-04,  2.54014637e-02,\n",
       "       -4.44826372e-02, -3.05528771e-02, -2.27481723e-02,  5.34625305e-03,\n",
       "       -1.77379996e-02,  8.93090665e-03,  6.29973272e-03, -4.71266881e-02,\n",
       "        9.71078314e-03, -1.98280867e-02, -1.95308924e-02,  2.61490606e-02,\n",
       "        2.61224667e-03, -2.84732524e-02, -8.45034514e-03, -6.73168302e-02,\n",
       "       -8.53152871e-02, -3.01743038e-02,  3.68126631e-02,  2.59252433e-02,\n",
       "       -6.74630627e-02, -5.72894327e-02, -1.90710574e-02, -2.98832282e-02,\n",
       "       -1.49018653e-02, -6.44191727e-03, -1.42152198e-02,  3.73985358e-02,\n",
       "        1.12889684e-03,  2.28630006e-02, -4.47166935e-02,  2.30517164e-02,\n",
       "        6.28995243e-04,  4.42759581e-02,  2.46650260e-02,  3.51332650e-02,\n",
       "       -3.61626558e-02, -4.75540161e-02,  1.82497650e-02,  3.07629649e-02,\n",
       "        1.00459764e-03, -1.84898898e-02, -2.19093199e-05,  7.50035569e-02,\n",
       "        3.62004526e-02,  6.58765212e-02, -1.86646841e-02,  4.20117714e-02,\n",
       "       -2.29519838e-03,  6.42548874e-02,  5.11614755e-02, -1.55825811e-02,\n",
       "       -7.13893271e-04,  3.42612378e-02, -6.07561739e-03,  2.43100375e-02,\n",
       "       -1.24312760e-02, -4.36683223e-02,  2.47560088e-02, -3.65800411e-02,\n",
       "        2.03333460e-02, -3.50792520e-02,  1.50017133e-02,  7.63922706e-02,\n",
       "        6.04432039e-02,  6.65943548e-02,  3.30562773e-03,  3.46693918e-02,\n",
       "       -1.60528708e-03, -2.37293225e-02,  9.55965184e-03, -8.56767129e-03,\n",
       "       -1.43413488e-02,  9.41571146e-02,  3.45746987e-02,  7.35701248e-02,\n",
       "        2.54632533e-02, -3.96390073e-02,  2.52090730e-02,  7.53591284e-02,\n",
       "       -3.82415764e-02, -3.73828709e-02, -5.41513897e-02,  2.40689218e-02,\n",
       "       -3.08087040e-02, -6.20012358e-03, -7.64314318e-03, -3.59188356e-02,\n",
       "        1.13591051e-03, -4.66335891e-03,  2.37280224e-02, -4.54729199e-02,\n",
       "       -1.95231556e-03,  1.30089903e-02, -4.03874815e-02,  3.14237550e-02,\n",
       "        3.25081944e-02,  2.98244655e-02, -7.06225866e-04, -8.04493651e-02,\n",
       "       -1.45465396e-02, -1.17485840e-02, -3.25348601e-02,  3.16704549e-02,\n",
       "       -4.22670431e-02,  6.71451315e-02, -1.01962626e-01, -3.84004600e-02,\n",
       "       -1.90570168e-02,  5.59219941e-02,  7.67457858e-03,  5.18109240e-02,\n",
       "        1.68128982e-02, -1.31116323e-02,  2.82035978e-03,  1.55522139e-03,\n",
       "       -5.03670773e-04, -3.61106247e-02, -6.84434315e-03,  1.76924858e-02,\n",
       "       -2.98449844e-02, -4.57745492e-02,  1.10833403e-02, -1.51629746e-02,\n",
       "        3.66883678e-03,  8.08090344e-02, -1.80434845e-02, -1.02005119e-03,\n",
       "       -4.84624499e-04,  3.22403163e-02, -1.65944993e-02,  1.84557727e-03,\n",
       "        5.07567227e-02,  1.58889610e-02, -6.26497939e-02, -1.95618309e-02,\n",
       "        4.34029959e-02, -5.68292923e-02,  1.05988391e-01, -4.80109118e-02,\n",
       "        1.00578032e-02,  2.19855942e-02, -3.14385891e-02,  1.16583658e-02,\n",
       "        3.97340506e-02, -1.13187302e-02,  5.83116822e-02,  2.77363975e-03,\n",
       "        6.33228794e-02,  4.29548509e-02,  2.16284245e-02,  3.85456197e-02,\n",
       "       -2.44158376e-02,  1.34007167e-02,  2.94843013e-03,  7.02527724e-03,\n",
       "       -1.87546574e-02,  4.76556793e-02,  6.15999401e-02,  1.85416285e-02,\n",
       "       -1.38640562e-02, -4.43654284e-02, -2.19827984e-02,  1.19857937e-02,\n",
       "       -3.77185643e-02, -6.42945617e-02, -2.67556366e-02,  5.12968600e-02,\n",
       "        2.78437715e-02, -6.28402382e-02, -3.17041352e-02,  2.21165232e-02,\n",
       "       -1.41522614e-02, -6.07152237e-03,  7.16667399e-02,  1.14129782e-02,\n",
       "        3.74981062e-03, -6.88135698e-02,  4.47597206e-02, -3.12533230e-02,\n",
       "        1.41535969e-02, -3.08248978e-02, -7.57665897e-04, -5.60957799e-03,\n",
       "        4.05324399e-02,  5.67558745e-04,  1.03436252e-02,  8.89484957e-02,\n",
       "       -8.93708505e-03, -6.23021908e-02,  2.01754831e-02, -1.27847502e-02,\n",
       "        1.61152035e-02, -1.23151252e-02,  2.49236617e-02,  2.02201847e-02,\n",
       "       -2.01465935e-02,  4.14759703e-02, -2.72540469e-02, -3.96626294e-02,\n",
       "       -2.26231553e-02,  1.40823529e-03,  1.52835445e-02, -6.26358911e-02,\n",
       "        6.85891137e-02,  2.12807525e-02, -4.11786921e-02,  7.12969303e-02,\n",
       "       -2.85412502e-02, -1.06836651e-02, -1.89546365e-02,  1.78563818e-02,\n",
       "       -3.75272185e-02,  6.14940363e-04,  4.38690819e-02,  1.56058948e-02,\n",
       "        3.15991277e-03,  5.58509305e-03, -5.97155234e-03,  2.85606217e-02,\n",
       "       -9.22782999e-03,  9.27612931e-03,  2.80325133e-02,  6.93220422e-02,\n",
       "       -3.44454981e-02, -2.25160196e-02,  2.57091895e-02, -4.39213877e-33,\n",
       "       -3.64304483e-02, -2.59271823e-03,  9.11506731e-03,  3.95197757e-02,\n",
       "        1.37440488e-02,  3.83445271e-03,  2.09223712e-03, -6.76700100e-03,\n",
       "        1.25045637e-02, -1.33823780e-02, -1.84269622e-03,  1.20098097e-02,\n",
       "        1.55764194e-02,  7.08822801e-04,  7.13026896e-02, -5.37558533e-02,\n",
       "        2.44811773e-02, -4.40049656e-02, -1.36816585e-02, -1.33414390e-02,\n",
       "       -2.93123703e-02, -1.21151609e-02,  6.02591224e-02,  1.02624986e-02,\n",
       "        3.59790660e-02, -3.84313837e-02,  2.23757215e-02,  1.09116184e-02,\n",
       "        6.93022609e-02,  1.61974709e-02, -3.05023789e-02,  4.06712964e-02,\n",
       "       -3.92036997e-02, -3.48173119e-02,  4.40173261e-02,  2.78183296e-02,\n",
       "       -5.45107294e-03, -2.34863274e-02,  9.80810262e-03,  2.96252631e-02,\n",
       "        4.15045060e-02, -8.76813382e-02, -8.35823864e-02, -2.17031799e-02,\n",
       "       -3.72131839e-02, -8.14555120e-03, -1.64231118e-02, -3.21022584e-03,\n",
       "        7.74318818e-03, -4.88729663e-02, -3.05721280e-03, -2.07577515e-02,\n",
       "        1.43916775e-02, -2.15989649e-02,  5.19236960e-02,  3.22398692e-02,\n",
       "        2.97001172e-02,  6.64230287e-02,  3.49241272e-02,  6.32981658e-02,\n",
       "        2.76507251e-02, -6.43676743e-02, -1.97426565e-02, -6.66220114e-02,\n",
       "       -2.80177128e-02, -2.66223624e-02, -1.15306703e-02, -2.93887989e-03,\n",
       "        2.88165901e-02, -3.48908380e-02,  1.28499269e-02,  2.38518473e-02,\n",
       "       -2.04858892e-02,  3.24630141e-02,  2.07587909e-02,  3.60320695e-02,\n",
       "        1.18891690e-02,  2.08263453e-02,  5.34499884e-02,  3.98997925e-02,\n",
       "        1.93191052e-03,  4.08157334e-02,  1.73661299e-02,  1.62020531e-02,\n",
       "       -3.99374068e-02, -5.42060360e-02, -9.92141105e-03, -2.20064539e-02,\n",
       "        2.27758586e-02, -3.69540718e-03, -5.12674861e-02, -3.43792774e-02,\n",
       "        2.70802993e-02,  6.55445643e-03, -8.59292075e-02, -6.78600818e-02,\n",
       "       -6.93697110e-03,  1.56281572e-02, -6.14052359e-03,  1.97633989e-02,\n",
       "       -2.56495923e-02, -8.55881255e-03, -6.69191638e-03, -1.37871550e-02,\n",
       "       -1.60989668e-02, -6.38105115e-03,  4.70549054e-02, -3.73784965e-03,\n",
       "       -2.61348244e-02,  9.47395805e-04,  5.62974485e-03, -4.70339619e-02,\n",
       "       -2.40904074e-02, -1.03060223e-01,  3.95706184e-02,  1.86298471e-02,\n",
       "        1.22608673e-02, -2.66108830e-02,  8.73120036e-03, -1.45036494e-02,\n",
       "       -2.18206346e-02, -5.02305217e-02, -1.87203605e-02, -1.50402505e-02,\n",
       "       -3.63762258e-03,  1.26318187e-02,  3.22695524e-02,  2.52542328e-02,\n",
       "       -2.95263734e-02, -1.22712450e-02, -1.14217680e-02, -9.44958162e-03,\n",
       "        1.85265733e-07, -3.20790224e-02,  2.90722698e-02,  1.50097897e-02,\n",
       "        4.58585322e-02, -4.58981059e-02,  8.51313621e-02,  1.87605675e-02,\n",
       "       -7.52918795e-03, -9.47744027e-03,  2.20604837e-02, -1.64591726e-02,\n",
       "        1.37806237e-02, -5.93535230e-03,  1.98825896e-02, -1.72281861e-02,\n",
       "       -5.15167788e-02,  7.51994699e-02, -2.18111202e-02,  1.30976059e-05,\n",
       "       -4.08614241e-02, -2.18479987e-02,  7.75561407e-02,  6.59543499e-02,\n",
       "        3.45364027e-02,  6.32865913e-03, -3.45287435e-02,  2.41718274e-02,\n",
       "       -5.22142574e-02, -4.00033547e-03, -4.70077544e-02, -7.21939234e-03,\n",
       "       -6.05985112e-02, -4.96253045e-03, -1.06796827e-02,  3.90087478e-02,\n",
       "       -4.15891269e-03,  5.15687615e-02,  1.44929932e-02,  8.72989930e-03,\n",
       "        5.83561771e-02, -4.20900173e-02, -3.73957236e-03, -4.08154540e-02,\n",
       "       -3.81657034e-02,  2.13405048e-03,  3.52091459e-03, -6.06541848e-03,\n",
       "       -2.75366828e-02, -1.17570609e-02, -2.33171950e-03,  2.78418884e-02,\n",
       "       -2.67389305e-02,  2.94055361e-02, -3.15133817e-02, -4.89008613e-03,\n",
       "       -3.41907423e-03,  4.42338362e-02,  1.56635828e-02,  1.01598399e-02,\n",
       "       -8.11970532e-02, -8.72944565e-06,  4.35417220e-02, -3.40955704e-03,\n",
       "        1.32463709e-01, -5.27367666e-02,  4.36557457e-02,  3.99109311e-02,\n",
       "        6.80548896e-35,  2.35433951e-02, -4.56788763e-02, -3.64246480e-02,\n",
       "        3.97049896e-02, -2.14084331e-02, -1.54703518e-03,  9.18157771e-02,\n",
       "       -7.23866327e-03,  7.68453535e-03,  2.62084529e-02, -2.25905678e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ec20632-b62e-496d-9f25-4c1bcd42210c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.03882700e-02,  2.78685484e-02, -1.18618105e-02,\n",
       "         1.81327220e-02,  1.21982570e-03, -1.42995454e-02,\n",
       "         1.96229313e-02,  2.07197927e-02, -2.23660693e-02,\n",
       "         4.75626662e-02,  1.77976135e-02, -8.00332427e-03,\n",
       "         2.53419187e-02,  5.26148640e-02,  8.44945665e-03,\n",
       "        -1.63943768e-02,  1.02661066e-02, -2.74856482e-02,\n",
       "         8.37067068e-02, -1.52885355e-02,  1.67682376e-02,\n",
       "        -3.97137273e-03, -2.74349079e-02,  5.02092130e-02,\n",
       "        -8.36520549e-03, -4.74075153e-02,  2.36915890e-02,\n",
       "        -1.01186074e-02, -2.82840580e-02,  7.94267375e-03,\n",
       "         4.21435460e-02, -4.19378374e-03, -1.91232879e-02,\n",
       "        -3.12785544e-02,  1.24685084e-06, -1.04428530e-02,\n",
       "        -2.19971761e-02, -8.66928175e-02, -1.88501901e-03,\n",
       "        -2.54772026e-02, -9.72971227e-03,  7.93310255e-02,\n",
       "        -3.55962925e-02, -3.05342750e-04, -1.12392586e-02,\n",
       "        -3.88931967e-02,  5.49314395e-02,  1.35208026e-01,\n",
       "        -8.19147602e-02,  1.18784951e-02, -9.01846774e-03,\n",
       "         1.92544367e-02, -2.82723829e-02, -3.29267196e-02,\n",
       "        -2.20107492e-02, -4.29836139e-02,  3.70104499e-02,\n",
       "        -4.80648950e-02,  9.49249044e-03,  3.51585485e-02,\n",
       "         4.88772281e-02, -3.28932740e-02, -1.24120079e-02,\n",
       "        -1.64292622e-02,  3.93721424e-02,  2.69109644e-02,\n",
       "         6.15458488e-02, -4.14122455e-03,  1.75675172e-02,\n",
       "         1.53993601e-02,  9.60063841e-03, -5.69581054e-04,\n",
       "        -4.83582616e-02,  4.25831787e-02,  1.10985609e-02,\n",
       "        -4.66182567e-02, -2.10591918e-03, -5.81461824e-02,\n",
       "         1.40412860e-02,  1.00883739e-02, -2.44590119e-02,\n",
       "         1.42714791e-02, -2.10581906e-02,  7.38854259e-02,\n",
       "        -2.23950054e-02,  1.38753178e-02, -1.33593439e-03,\n",
       "         9.21319053e-03, -2.84222253e-02, -4.04208759e-03,\n",
       "        -1.71393137e-02, -8.46527983e-03, -2.83983871e-02,\n",
       "        -3.69299874e-02, -9.47201177e-02, -3.26580442e-02,\n",
       "         2.60050166e-02,  1.31178899e-02,  1.51670696e-02,\n",
       "        -2.12381291e-03,  1.48177920e-02,  1.37817087e-02,\n",
       "         1.25303064e-02, -5.01471339e-03,  3.56062278e-02,\n",
       "         5.93454354e-02, -5.03398143e-02, -9.55990795e-03,\n",
       "        -7.23669231e-02,  9.45842639e-03,  1.54202767e-02,\n",
       "        -7.03745335e-03, -3.10014226e-02, -8.86358693e-03,\n",
       "        -2.98000928e-02, -8.84007812e-02, -2.25059129e-02,\n",
       "        -3.25824358e-02,  4.78070043e-02,  2.14020722e-03,\n",
       "         1.37761864e-03, -1.25065912e-02, -1.15712341e-02,\n",
       "         2.34021675e-02,  3.43836239e-03,  2.69363150e-02,\n",
       "        -6.23307154e-02, -5.29250037e-03,  1.73164241e-03,\n",
       "         3.20438966e-02,  2.13047402e-04, -1.54123809e-02,\n",
       "         5.08342907e-02, -4.52312939e-02, -1.67427827e-02,\n",
       "        -3.47918086e-02, -4.16715518e-02, -2.34929398e-02,\n",
       "         2.40796595e-03, -2.15250645e-02,  3.07007483e-03,\n",
       "         2.54971068e-02,  3.60133648e-02,  2.68477760e-02,\n",
       "        -4.22385745e-02, -2.45388784e-02,  3.93798761e-02,\n",
       "         6.31313445e-03,  2.03843545e-02, -2.22934633e-02,\n",
       "        -7.87332747e-03, -1.47401225e-02,  4.87235375e-02,\n",
       "        -2.55933180e-02, -1.08920811e-02, -3.37023064e-02,\n",
       "         4.69094962e-02,  1.95820946e-02,  4.13415115e-03,\n",
       "         2.72842813e-02,  4.72923712e-04,  2.55069938e-02,\n",
       "        -5.26176244e-02,  3.57674882e-02, -5.46486583e-03,\n",
       "        -3.90751287e-02, -4.51455973e-02, -1.37631288e-02,\n",
       "         5.50721101e-02,  3.80344018e-02, -4.58983816e-02,\n",
       "         4.83396463e-03, -2.92574242e-02, -4.76552360e-03,\n",
       "         9.17753503e-02, -9.70399827e-02,  1.05631799e-01,\n",
       "        -5.64411655e-02, -6.33300170e-02,  3.45335230e-02,\n",
       "        -5.77132925e-02, -1.21777318e-01,  9.45339818e-03,\n",
       "         2.02731118e-02,  2.63032094e-02,  3.96900298e-03,\n",
       "        -3.88275348e-02, -1.57009419e-02, -3.47952209e-02,\n",
       "        -3.07987947e-02,  3.24619897e-02, -4.84479815e-02,\n",
       "         4.39476641e-03, -1.72206610e-02,  1.15584167e-04,\n",
       "        -3.72782163e-02, -5.17302640e-02, -1.91914961e-02,\n",
       "        -3.10722739e-02,  4.77238325e-03, -5.49007133e-02,\n",
       "        -1.40049309e-02,  2.99300998e-02,  9.23176780e-02,\n",
       "        -2.96304077e-02,  2.45515388e-02,  3.50713581e-02,\n",
       "        -5.64088020e-03,  1.57490168e-02,  2.08431743e-02,\n",
       "         5.11531830e-02,  7.25738937e-03,  4.40726662e-03,\n",
       "        -2.58071963e-02,  4.99892468e-03, -1.47745281e-03,\n",
       "        -4.42324718e-03,  4.48388569e-02,  7.79227838e-02,\n",
       "         1.65748112e-02, -3.80822457e-02,  3.76827866e-02,\n",
       "         1.02415621e-01, -1.61058474e-02,  7.32477158e-02,\n",
       "        -1.11488895e-02,  3.81630063e-02,  2.02278346e-02,\n",
       "        -1.23596732e-02,  2.38338336e-02, -2.99291667e-02,\n",
       "        -7.08034076e-03,  1.23009877e-02, -6.69539114e-03,\n",
       "        -6.65793791e-02,  6.94696307e-02,  1.02031408e-02,\n",
       "        -2.23912131e-02, -1.79656334e-02, -3.10914274e-02,\n",
       "        -3.04419678e-02, -2.43376065e-02,  2.62913052e-02,\n",
       "        -1.44890565e-02, -3.44527364e-02,  3.69897671e-03,\n",
       "         2.34961864e-02, -2.20465679e-02, -6.40620217e-02,\n",
       "        -3.29653583e-02, -1.13152880e-02,  4.46261466e-02,\n",
       "         2.82178354e-02, -1.32326260e-02, -2.48316675e-02,\n",
       "        -4.16194461e-02, -3.17105167e-02, -2.90316530e-03,\n",
       "        -2.58373823e-02, -2.38407478e-02,  4.09952924e-02,\n",
       "        -3.72038931e-02,  3.80427018e-02,  2.60184668e-02,\n",
       "         3.78452502e-02, -1.22929495e-02, -1.78747308e-02,\n",
       "         2.22684685e-02, -1.39293233e-02,  3.33376718e-03,\n",
       "        -1.01043740e-02, -9.42678899e-02,  2.93327589e-02,\n",
       "        -2.11533997e-02, -8.28083977e-03,  9.39183310e-03,\n",
       "         7.01194480e-02, -2.47647930e-02, -7.45412335e-03,\n",
       "         1.81595180e-02,  2.10113544e-02,  5.30431904e-02,\n",
       "        -1.83114279e-02,  2.45678052e-02,  1.81325637e-02,\n",
       "        -1.36736697e-02, -2.25669960e-03,  2.27259938e-02,\n",
       "        -1.32561419e-02,  5.31734191e-02,  2.84625031e-03,\n",
       "        -1.26052834e-02,  5.37055321e-02, -2.62218323e-02,\n",
       "         6.28261864e-02, -3.38792503e-02,  1.24345170e-02,\n",
       "         3.83227295e-03,  2.31523160e-02, -7.25013539e-02,\n",
       "        -4.14387556e-03, -4.29395810e-02, -9.25691426e-03,\n",
       "        -1.02920374e-02, -2.94399858e-02, -1.51161207e-02,\n",
       "         1.03488723e-02, -8.83047283e-03,  7.79084396e-03,\n",
       "         6.15880452e-02, -2.56217867e-02,  2.67890971e-02,\n",
       "        -3.48655246e-02, -3.35103758e-02,  4.58869301e-02,\n",
       "         2.87142601e-02, -1.73843671e-02,  9.46802273e-02,\n",
       "        -2.42618341e-02,  2.83706915e-02,  5.47288777e-03,\n",
       "        -3.05395722e-02, -2.04882082e-02,  1.14950901e-02,\n",
       "        -2.06157099e-02, -4.73046526e-02, -5.66288829e-04,\n",
       "         2.54014637e-02, -4.44826372e-02, -3.05528771e-02,\n",
       "        -2.27481723e-02,  5.34625305e-03, -1.77379996e-02,\n",
       "         8.93090665e-03,  6.29973272e-03, -4.71266881e-02,\n",
       "         9.71078314e-03, -1.98280867e-02, -1.95308924e-02,\n",
       "         2.61490606e-02,  2.61224667e-03, -2.84732524e-02,\n",
       "        -8.45034514e-03, -6.73168302e-02, -8.53152871e-02,\n",
       "        -3.01743038e-02,  3.68126631e-02,  2.59252433e-02,\n",
       "        -6.74630627e-02, -5.72894327e-02, -1.90710574e-02,\n",
       "        -2.98832282e-02, -1.49018653e-02, -6.44191727e-03,\n",
       "        -1.42152198e-02,  3.73985358e-02,  1.12889684e-03,\n",
       "         2.28630006e-02, -4.47166935e-02,  2.30517164e-02,\n",
       "         6.28995243e-04,  4.42759581e-02,  2.46650260e-02,\n",
       "         3.51332650e-02, -3.61626558e-02, -4.75540161e-02,\n",
       "         1.82497650e-02,  3.07629649e-02,  1.00459764e-03,\n",
       "        -1.84898898e-02, -2.19093199e-05,  7.50035569e-02,\n",
       "         3.62004526e-02,  6.58765212e-02, -1.86646841e-02,\n",
       "         4.20117714e-02, -2.29519838e-03,  6.42548874e-02,\n",
       "         5.11614755e-02, -1.55825811e-02, -7.13893271e-04,\n",
       "         3.42612378e-02, -6.07561739e-03,  2.43100375e-02,\n",
       "        -1.24312760e-02, -4.36683223e-02,  2.47560088e-02,\n",
       "        -3.65800411e-02,  2.03333460e-02, -3.50792520e-02,\n",
       "         1.50017133e-02,  7.63922706e-02,  6.04432039e-02,\n",
       "         6.65943548e-02,  3.30562773e-03,  3.46693918e-02,\n",
       "        -1.60528708e-03, -2.37293225e-02,  9.55965184e-03,\n",
       "        -8.56767129e-03, -1.43413488e-02,  9.41571146e-02,\n",
       "         3.45746987e-02,  7.35701248e-02,  2.54632533e-02,\n",
       "        -3.96390073e-02,  2.52090730e-02,  7.53591284e-02,\n",
       "        -3.82415764e-02, -3.73828709e-02, -5.41513897e-02,\n",
       "         2.40689218e-02, -3.08087040e-02, -6.20012358e-03,\n",
       "        -7.64314318e-03, -3.59188356e-02,  1.13591051e-03,\n",
       "        -4.66335891e-03,  2.37280224e-02, -4.54729199e-02,\n",
       "        -1.95231556e-03,  1.30089903e-02, -4.03874815e-02,\n",
       "         3.14237550e-02,  3.25081944e-02,  2.98244655e-02,\n",
       "        -7.06225866e-04, -8.04493651e-02, -1.45465396e-02,\n",
       "        -1.17485840e-02, -3.25348601e-02,  3.16704549e-02,\n",
       "        -4.22670431e-02,  6.71451315e-02, -1.01962626e-01,\n",
       "        -3.84004600e-02, -1.90570168e-02,  5.59219941e-02,\n",
       "         7.67457858e-03,  5.18109240e-02,  1.68128982e-02,\n",
       "        -1.31116323e-02,  2.82035978e-03,  1.55522139e-03,\n",
       "        -5.03670773e-04, -3.61106247e-02, -6.84434315e-03,\n",
       "         1.76924858e-02, -2.98449844e-02, -4.57745492e-02,\n",
       "         1.10833403e-02, -1.51629746e-02,  3.66883678e-03,\n",
       "         8.08090344e-02, -1.80434845e-02, -1.02005119e-03,\n",
       "        -4.84624499e-04,  3.22403163e-02, -1.65944993e-02,\n",
       "         1.84557727e-03,  5.07567227e-02,  1.58889610e-02,\n",
       "        -6.26497939e-02, -1.95618309e-02,  4.34029959e-02,\n",
       "        -5.68292923e-02,  1.05988391e-01, -4.80109118e-02,\n",
       "         1.00578032e-02,  2.19855942e-02, -3.14385891e-02,\n",
       "         1.16583658e-02,  3.97340506e-02, -1.13187302e-02,\n",
       "         5.83116822e-02,  2.77363975e-03,  6.33228794e-02,\n",
       "         4.29548509e-02,  2.16284245e-02,  3.85456197e-02,\n",
       "        -2.44158376e-02,  1.34007167e-02,  2.94843013e-03,\n",
       "         7.02527724e-03, -1.87546574e-02,  4.76556793e-02,\n",
       "         6.15999401e-02,  1.85416285e-02, -1.38640562e-02,\n",
       "        -4.43654284e-02, -2.19827984e-02,  1.19857937e-02,\n",
       "        -3.77185643e-02, -6.42945617e-02, -2.67556366e-02,\n",
       "         5.12968600e-02,  2.78437715e-02, -6.28402382e-02,\n",
       "        -3.17041352e-02,  2.21165232e-02, -1.41522614e-02,\n",
       "        -6.07152237e-03,  7.16667399e-02,  1.14129782e-02,\n",
       "         3.74981062e-03, -6.88135698e-02,  4.47597206e-02,\n",
       "        -3.12533230e-02,  1.41535969e-02, -3.08248978e-02,\n",
       "        -7.57665897e-04, -5.60957799e-03,  4.05324399e-02,\n",
       "         5.67558745e-04,  1.03436252e-02,  8.89484957e-02,\n",
       "        -8.93708505e-03, -6.23021908e-02,  2.01754831e-02,\n",
       "        -1.27847502e-02,  1.61152035e-02, -1.23151252e-02,\n",
       "         2.49236617e-02,  2.02201847e-02, -2.01465935e-02,\n",
       "         4.14759703e-02, -2.72540469e-02, -3.96626294e-02,\n",
       "        -2.26231553e-02,  1.40823529e-03,  1.52835445e-02,\n",
       "        -6.26358911e-02,  6.85891137e-02,  2.12807525e-02,\n",
       "        -4.11786921e-02,  7.12969303e-02, -2.85412502e-02,\n",
       "        -1.06836651e-02, -1.89546365e-02,  1.78563818e-02,\n",
       "        -3.75272185e-02,  6.14940363e-04,  4.38690819e-02,\n",
       "         1.56058948e-02,  3.15991277e-03,  5.58509305e-03,\n",
       "        -5.97155234e-03,  2.85606217e-02, -9.22782999e-03,\n",
       "         9.27612931e-03,  2.80325133e-02,  6.93220422e-02,\n",
       "        -3.44454981e-02, -2.25160196e-02,  2.57091895e-02,\n",
       "        -4.39213877e-33, -3.64304483e-02, -2.59271823e-03,\n",
       "         9.11506731e-03,  3.95197757e-02,  1.37440488e-02,\n",
       "         3.83445271e-03,  2.09223712e-03, -6.76700100e-03,\n",
       "         1.25045637e-02, -1.33823780e-02, -1.84269622e-03,\n",
       "         1.20098097e-02,  1.55764194e-02,  7.08822801e-04,\n",
       "         7.13026896e-02, -5.37558533e-02,  2.44811773e-02,\n",
       "        -4.40049656e-02, -1.36816585e-02, -1.33414390e-02,\n",
       "        -2.93123703e-02, -1.21151609e-02,  6.02591224e-02,\n",
       "         1.02624986e-02,  3.59790660e-02, -3.84313837e-02,\n",
       "         2.23757215e-02,  1.09116184e-02,  6.93022609e-02,\n",
       "         1.61974709e-02, -3.05023789e-02,  4.06712964e-02,\n",
       "        -3.92036997e-02, -3.48173119e-02,  4.40173261e-02,\n",
       "         2.78183296e-02, -5.45107294e-03, -2.34863274e-02,\n",
       "         9.80810262e-03,  2.96252631e-02,  4.15045060e-02,\n",
       "        -8.76813382e-02, -8.35823864e-02, -2.17031799e-02,\n",
       "        -3.72131839e-02, -8.14555120e-03, -1.64231118e-02,\n",
       "        -3.21022584e-03,  7.74318818e-03, -4.88729663e-02,\n",
       "        -3.05721280e-03, -2.07577515e-02,  1.43916775e-02,\n",
       "        -2.15989649e-02,  5.19236960e-02,  3.22398692e-02,\n",
       "         2.97001172e-02,  6.64230287e-02,  3.49241272e-02,\n",
       "         6.32981658e-02,  2.76507251e-02, -6.43676743e-02,\n",
       "        -1.97426565e-02, -6.66220114e-02, -2.80177128e-02,\n",
       "        -2.66223624e-02, -1.15306703e-02, -2.93887989e-03,\n",
       "         2.88165901e-02, -3.48908380e-02,  1.28499269e-02,\n",
       "         2.38518473e-02, -2.04858892e-02,  3.24630141e-02,\n",
       "         2.07587909e-02,  3.60320695e-02,  1.18891690e-02,\n",
       "         2.08263453e-02,  5.34499884e-02,  3.98997925e-02,\n",
       "         1.93191052e-03,  4.08157334e-02,  1.73661299e-02,\n",
       "         1.62020531e-02, -3.99374068e-02, -5.42060360e-02,\n",
       "        -9.92141105e-03, -2.20064539e-02,  2.27758586e-02,\n",
       "        -3.69540718e-03, -5.12674861e-02, -3.43792774e-02,\n",
       "         2.70802993e-02,  6.55445643e-03, -8.59292075e-02,\n",
       "        -6.78600818e-02, -6.93697110e-03,  1.56281572e-02,\n",
       "        -6.14052359e-03,  1.97633989e-02, -2.56495923e-02,\n",
       "        -8.55881255e-03, -6.69191638e-03, -1.37871550e-02,\n",
       "        -1.60989668e-02, -6.38105115e-03,  4.70549054e-02,\n",
       "        -3.73784965e-03, -2.61348244e-02,  9.47395805e-04,\n",
       "         5.62974485e-03, -4.70339619e-02, -2.40904074e-02,\n",
       "        -1.03060223e-01,  3.95706184e-02,  1.86298471e-02,\n",
       "         1.22608673e-02, -2.66108830e-02,  8.73120036e-03,\n",
       "        -1.45036494e-02, -2.18206346e-02, -5.02305217e-02,\n",
       "        -1.87203605e-02, -1.50402505e-02, -3.63762258e-03,\n",
       "         1.26318187e-02,  3.22695524e-02,  2.52542328e-02,\n",
       "        -2.95263734e-02, -1.22712450e-02, -1.14217680e-02,\n",
       "        -9.44958162e-03,  1.85265733e-07, -3.20790224e-02,\n",
       "         2.90722698e-02,  1.50097897e-02,  4.58585322e-02,\n",
       "        -4.58981059e-02,  8.51313621e-02,  1.87605675e-02,\n",
       "        -7.52918795e-03, -9.47744027e-03,  2.20604837e-02,\n",
       "        -1.64591726e-02,  1.37806237e-02, -5.93535230e-03,\n",
       "         1.98825896e-02, -1.72281861e-02, -5.15167788e-02,\n",
       "         7.51994699e-02, -2.18111202e-02,  1.30976059e-05,\n",
       "        -4.08614241e-02, -2.18479987e-02,  7.75561407e-02,\n",
       "         6.59543499e-02,  3.45364027e-02,  6.32865913e-03,\n",
       "        -3.45287435e-02,  2.41718274e-02, -5.22142574e-02,\n",
       "        -4.00033547e-03, -4.70077544e-02, -7.21939234e-03,\n",
       "        -6.05985112e-02, -4.96253045e-03, -1.06796827e-02,\n",
       "         3.90087478e-02, -4.15891269e-03,  5.15687615e-02,\n",
       "         1.44929932e-02,  8.72989930e-03,  5.83561771e-02,\n",
       "        -4.20900173e-02, -3.73957236e-03, -4.08154540e-02,\n",
       "        -3.81657034e-02,  2.13405048e-03,  3.52091459e-03,\n",
       "        -6.06541848e-03, -2.75366828e-02, -1.17570609e-02,\n",
       "        -2.33171950e-03,  2.78418884e-02, -2.67389305e-02,\n",
       "         2.94055361e-02, -3.15133817e-02, -4.89008613e-03,\n",
       "        -3.41907423e-03,  4.42338362e-02,  1.56635828e-02,\n",
       "         1.01598399e-02, -8.11970532e-02, -8.72944565e-06,\n",
       "         4.35417220e-02, -3.40955704e-03,  1.32463709e-01,\n",
       "        -5.27367666e-02,  4.36557457e-02,  3.99109311e-02,\n",
       "         6.80548896e-35,  2.35433951e-02, -4.56788763e-02,\n",
       "        -3.64246480e-02,  3.97049896e-02, -2.14084331e-02,\n",
       "        -1.54703518e-03,  9.18157771e-02, -7.23866327e-03,\n",
       "         7.68453535e-03,  2.62084529e-02, -2.25905678e-03]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10f9a92a-b2ef-4793-9f7a-3cd3738ce50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.3844838, 1.4039097]], dtype=float32), array([[3, 2]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(svec, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "566a36ef-68b9-4c0d-a389-91321a89154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, I = index.search(svec, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "523a440f-47b2-421c-8714-5cde08762beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acbf1ae0-d51e-43e8-b23b-db7f9d95a40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vibrant color jeans for male are becoming a trend</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These are the latest fashion trends for this week</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text category\n",
       "3  Vibrant color jeans for male are becoming a trend  Fashion\n",
       "2  These are the latest fashion trends for this week  Fashion"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a01c4139-a50a-4b57-a177-8bd9156c0c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to buy a polo t-shirt'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78593fb7-c899-467b-89e4-39a7300a7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import time\n",
    "import langchain\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae93164c-eb48-41a4-90e7-925b1204aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04736b5-e0b0-45cd-8c99-af4b35b724bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e355b23-eaf8-481f-a9ec-985de4e675e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = UnstructuredURLLoader(urls=[\n",
    "    \"https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-buzz-article.html\",\n",
    "    \"https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-article.html\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6d2d60-9e15-40f5-bcc9-03524701a202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loaders.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c330e71-095a-4492-8663-88bbd0a620ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa4b092a-7ad3-4327-b3b5-be7ff11bd110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = text_splitter.split_documents(data)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03835a9-7d19-4e7d-a608-233b6e6c80f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='than $75 billion stash of Bitcoin — a blueprint followed by other public companies. A firm tied to President Trump and his family owns 40% of World Liberty Financial’s parent company, and billions of its tokens, according to its website. Other co-founders include Trump’s sons Donald Trump Jr. and Barron Trump, and Witkoff’s son Alex Witkoff. President Trump and Steve Witkoff are each labeled “co-founder emeritus.” Crypto ventures, including World Liberty Financial and a Trump memecoin announced on his inauguration weekend, added at least $620 million to Donald Trump’s fortune in months, according to the Bloomberg Billionaires Index. And the Trumps are linked to an increasing number of companies entwining cryptocurrencies with public markets. Trump Media &amp; Technology Group Corp., the parent company of Truth Social, is working on a plan to sell Bitcoin ETFs. Eric Trump co-founded a new Bitcoin mining venture, in partnership with Hut 8 Corp., that will spin off into a separate public', metadata={'source': 'https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-buzz-article.html'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "841a94bc-e966-4f04-b0cb-91c033d9c241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='[HTTP_X_FORWARDED_FOR] => 78.16.182.232, 23.72.36.238,23.218.249.29,34.36.26.240,35.191.42.69\\n    [HTTP_CACHE_CONTROL] => no-cache, max-age=0\\n    [HTTP_X_CLOUD_TRACE_CONTEXT] => 038c28a0fa8da5ab63523c777a055035/16582992014565609263\\n    [HTTP_X_FORWARDED_PROTO] => http\\n    [HTTP_ACCEPT_ENCODING] => gzip\\n    [HTTP_X_ENVOY_EXTERNAL_ADDRESS] => 35.191.42.69\\n    [HTTP_X_REQUEST_ID] => 85fbca63-64e2-4755-8f42-a3108da91789\\n    [HTTP_X_ENVOY_ATTEMPT_COUNT] => 1\\n    [HTTP_X_FORWARDED_CLIENT_CERT] => By=spiffe://prj-prod-svc-mc-std77.svc.id.goog/ns/prod-mc-microsites/sa/ksa-std-prod-gdpr;Hash=a921a76b025db676d34837d8e58bc1f7ee4dc9f2209ec5747f6036cf82a0c6cc;Subject=\"OU=istio_v1_cloud_workload,O=Google LLC,L=Mountain View,ST=California,C=US\";URI=spiffe://prj-prod-svc-mc-std77.svc.id.goog/ns/istio-system/sa/istio-ingressgateway-service-account\\n    [HTTP_X_B3_TRACEID] => abcdb60e799e0305c93e7a15f7fefe38\\n    [HTTP_X_B3_SPANID] => b62755f1e664fc92\\n    [HTTP_X_B3_PARENTSPANID] => c93e7a15f7fefe38', metadata={'source': 'https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-buzz-article.html'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2024c67-3c14-41d9-871b-7e343b75f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d81b1f9-3d8e-4f82-8529-67483750083c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99.6\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "print(openai.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c706ab-defe-4043-9bf4-e620a5b25179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in ./.venv/lib/python3.11/site-packages (from openai==0.28) (2.32.4)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from openai==0.28) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from openai==0.28) (3.12.15)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2025.8.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->openai==0.28) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->openai==0.28) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp->openai==0.28) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->openai==0.28) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in ./.venv/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.14.1)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.99.6\n",
      "    Uninstalling openai-1.99.6:\n",
      "      Successfully uninstalled openai-1.99.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.3.29 requires openai<2.0.0,>=1.86.0, but you have openai 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed openai-0.28.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b24ba5-11b7-4fef-b45c-757de6983356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"vector_index.pkl\", \"rb\") as f:\n",
    "    vectorindex_openai = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c563e88-3620-4ed0-92d5-06a6f729e26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646df835-838b-4bbb-8fb6-e399ed7de1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"vector_index.pkl\", \"rb\") as f:\n",
    "    vectorindex_openai = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e4a28f3-7b3e-4940-97d7-a3c5c015cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai<1.0 in ./.venv/lib/python3.11/site-packages (0.28.0)\n",
      "Collecting openai<1.0\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langchain<0.3,>=0.2.11\n",
      "  Downloading langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-openai<0.2,>=0.1.7\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-community<0.3,>=0.2.11\n",
      "  Downloading langchain_community-0.2.19-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.11/site-packages (1.7.4)\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.11.0.post1-cp311-cp311-macosx_13_0_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: requests>=2.20 in ./.venv/lib/python3.11/site-packages (from openai<1.0) (2.32.4)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from openai<1.0) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from openai<1.0) (3.12.15)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain<0.3,>=0.2.11) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.11/site-packages (from langchain<0.3,>=0.2.11) (2.0.42)\n",
      "Collecting langchain-core<0.3.0,>=0.2.43 (from langchain<0.3,>=0.2.11)\n",
      "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3,>=0.2.11)\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.3,>=0.2.11)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.11/site-packages (from langchain<0.3,>=0.2.11) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.11/site-packages (from langchain<0.3,>=0.2.11) (2.11.7)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain<0.3,>=0.2.11) (8.5.0)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-openai<0.2,>=0.1.7\n",
      "  Downloading langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.22-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_openai-0.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_openai-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting openai<1.0\n",
      "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading openai-0.27.10-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading openai-0.27.9-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading openai-0.27.8-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading openai-0.27.7-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading openai-0.27.6-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading openai-0.27.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading openai-0.27.4-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading openai-0.27.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading openai-0.27.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading openai-0.27.1.tar.gz (57 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.26.4.tar.gz (55 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.26.3.tar.gz (55 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.26.2.tar.gz (55 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.26.1.tar.gz (55 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.26.0.tar.gz (54 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.25.0.tar.gz (44 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.2.3 in ./.venv/lib/python3.11/site-packages (from openai<1.0) (2.3.1)\n",
      "Collecting pandas-stubs>=1.1.0.11 (from openai<1.0)\n",
      "  Downloading pandas_stubs-2.3.0.250703-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting openpyxl>=3.0.7 (from openai<1.0)\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: typing_extensions in ./.venv/lib/python3.11/site-packages (from openai<1.0) (4.14.1)\n",
      "Collecting openai<1.0\n",
      "  Downloading openai-0.24.0.tar.gz (44 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.23.1.tar.gz (43 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.23.0.tar.gz (43 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.22.1.tar.gz (43 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.22.0.tar.gz (43 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.20.0.tar.gz (42 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.19.0.tar.gz (42 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.18.1.tar.gz (42 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.18.0.tar.gz (42 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.16.0.tar.gz (41 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.15.0.tar.gz (40 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.14.0.tar.gz (40 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.13.0.tar.gz (37 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.12.0.tar.gz (36 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.11.6.tar.gz (33 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.11.5.tar.gz (466 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.11.4.tar.gz (152 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.11.3.tar.gz (150 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.11.2.tar.gz (150 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.11.1.tar.gz (150 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.11.0.tar.gz (150 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.10.5.tar.gz (157 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.10.4.tar.gz (157 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.10.3.tar.gz (157 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.10.2.tar.gz (156 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.10.1.tar.gz (155 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.10.0.tar.gz (155 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.9.4.tar.gz (156 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.9.3.tar.gz (155 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.9.2.tar.gz (155 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.9.1.tar.gz (156 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.9.0.tar.gz (155 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.8.0.tar.gz (147 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.7.0.tar.gz (147 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.6.4.tar.gz (159 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.6.3.tar.gz (158 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.6.2.tar.gz (158 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.6.1.tar.gz (158 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.6.0.tar.gz (159 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.4.0.tar.gz (158 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.3.0.tar.gz (157 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.2.6.tar.gz (157 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.2.5.tar.gz (157 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.2.4.tar.gz (157 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.2.3.tar.gz (157 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.2.1.tar.gz (154 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.2.0.tar.gz (154 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.1.3.tar.gz (155 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.1.2.tar.gz (155 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.1.1.tar.gz (156 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.1.0.tar.gz (168 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading openai-0.0.2.tar.gz (741 bytes)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[20 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/fariskajani/Code/genai-finance/.venv/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 143, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/sn/z9rqrx2562d9qq96khj5vjrc0000gn/T/pip-build-env-xmf_o_q6/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 331, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/sn/z9rqrx2562d9qq96khj5vjrc0000gn/T/pip-build-env-xmf_o_q6/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 301, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/sn/z9rqrx2562d9qq96khj5vjrc0000gn/T/pip-build-env-xmf_o_q6/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 512, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super().run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/sn/z9rqrx2562d9qq96khj5vjrc0000gn/T/pip-build-env-xmf_o_q6/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 317, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 6, in <module>\n",
      "  \u001b[31m   \u001b[0m RuntimeError: This package is a placeholder package on the public PyPI instance, and is not the correct version to install. If you are having trouble figuring out the correct package to install, please contact us.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"openai<1.0\" \\\n",
    "  \"langchain>=0.2.11,<0.3\" \\\n",
    "  \"langchain-openai>=0.1.7,<0.2\" \\\n",
    "  \"langchain-community>=0.2.11,<0.3\" \\\n",
    "  tiktoken faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d30c948-c9da-453d-bdaf-d246107987f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.2.12\n",
      "  Using cached langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core==0.2.36\n",
      "  Using cached langchain_core-0.2.36-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-community==0.2.11\n",
      "  Using cached langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-openai==0.1.7\n",
      "  Using cached langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.11/site-packages (0.28.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.99.7-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain==0.2.12) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.11/site-packages (from langchain==0.2.12) (2.0.42)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.11/site-packages (from langchain==0.2.12) (3.12.15)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.12)\n",
      "  Using cached langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.12)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.11/site-packages (from langchain==0.2.12) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.11/site-packages (from langchain==0.2.12) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langchain==0.2.12) (2.32.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain==0.2.12) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core==0.2.36) (1.33)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core==0.2.36)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.11/site-packages (from langchain-core==0.2.36) (4.14.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.11/site-packages (from langchain-community==0.2.11) (0.6.7)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.11/site-packages (from langchain-openai==0.1.7) (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.12) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.12) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.12) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.12) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.12) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.12) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.12) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.11) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.11) (0.9.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.36) (3.0.0)\n",
      "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.12)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.12) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.12) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.2.12) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.2.12) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.2.12) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.2.12) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.2.12) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.12) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.7) (2025.7.34)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.11) (1.1.0)\n",
      "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.36-py3-none-any.whl (395 kB)\n",
      "Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
      "Downloading openai-1.99.7-py3-none-any.whl (786 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: packaging, openai, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community\n",
      "\u001b[2K  Attempting uninstall: packaging\n",
      "\u001b[2K    Found existing installation: packaging 25.0\n",
      "\u001b[2K    Uninstalling packaging-25.0:\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0\n",
      "\u001b[2K  Attempting uninstall: openai\n",
      "\u001b[2K    Found existing installation: openai 0.28.0\n",
      "\u001b[2K    Uninstalling openai-0.28.0:\n",
      "\u001b[2K      Successfully uninstalled openai-0.28.0\n",
      "\u001b[2K  Attempting uninstall: langsmith━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/8\u001b[0m [openai]\n",
      "\u001b[2K    Found existing installation: langsmith 0.0.92━━━━━━━━━━━━━\u001b[0m \u001b[32m1/8\u001b[0m [openai]\n",
      "\u001b[2K    Uninstalling langsmith-0.0.92:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/8\u001b[0m [openai]\n",
      "\u001b[2K      Successfully uninstalled langsmith-0.0.92━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/8\u001b[0m [openai]\n",
      "\u001b[2K  Attempting uninstall: langchain-core━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/8\u001b[0m [langsmith]\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.74━━━━━━━━\u001b[0m \u001b[32m2/8\u001b[0m [langsmith]\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.74:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/8\u001b[0m [langsmith]\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.74━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/8\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain-text-splitters━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/8\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain-text-splitters 0.3.9[0m \u001b[32m3/8\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-text-splitters-0.3.9:━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/8\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-text-splitters-0.3.9━\u001b[0m \u001b[32m3/8\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain-openai━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/8\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain-openai 0.3.29━━━━━━\u001b[0m \u001b[32m3/8\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-openai-0.3.29:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/8\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-openai-0.3.29━━━━━━━━\u001b[0m \u001b[32m3/8\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/8\u001b[0m [langchain-openai]\n",
      "\u001b[2K    Found existing installation: langchain 0.0.312━━━━━━━━━━━━\u001b[0m \u001b[32m5/8\u001b[0m [langchain-openai]\n",
      "\u001b[2K    Uninstalling langchain-0.0.312:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6/8\u001b[0m [langchain]ai]\n",
      "\u001b[2K      Successfully uninstalled langchain-0.0.312\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6/8\u001b[0m [langchain]\n",
      "\u001b[2K  Attempting uninstall: langchain-community[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6/8\u001b[0m [langchain]\n",
      "\u001b[2K    Found existing installation: langchain-community 0.3.27━━━\u001b[0m \u001b[32m6/8\u001b[0m [langchain]\n",
      "\u001b[2K    Uninstalling langchain-community-0.3.27:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m7/8\u001b[0m [langchain-community]\n",
      "\u001b[2K      Successfully uninstalled langchain-community-0.3.27m━━━━\u001b[0m \u001b[32m7/8\u001b[0m [langchain-community]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-0.2.12 langchain-community-0.2.11 langchain-core-0.2.36 langchain-openai-0.1.7 langchain-text-splitters-0.2.2 langsmith-0.1.147 openai-1.99.7 packaging-24.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \\\n",
    "  \"langchain==0.2.12\" \\\n",
    "  \"langchain-core==0.2.36\" \\\n",
    "  \"langchain-community==0.2.11\" \\\n",
    "  \"langchain-openai==0.1.7\" \\\n",
    "  openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c17986fe-0f1e-42ea-adc5-b800610e1b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain: 0.2.12\n",
      "langchain-community: 0.2.11\n",
      "langchain-openai: 0.1.7\n",
      "openai: 1.99.7\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import langchain, openai, pkg_resources\n",
    "\n",
    "print(\"langchain:\", langchain.__version__)\n",
    "print(\"langchain-community:\", pkg_resources.get_distribution(\"langchain-community\").version)\n",
    "print(\"langchain-openai:\", pkg_resources.get_distribution(\"langchain-openai\").version)\n",
    "print(\"openai:\", openai.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3211bd2f-6267-4552-8c0e-654679442d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# continue with FAISS, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06adcdda-6e32-423c-b9ad-d39eb899ccde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://www.reuters.com/technology/ai/\",\n",
    "    \"https://www.bbc.com/news/technology\"\n",
    "]\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "docs_raw = loader.load()\n",
    "len(docs_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c78858a8-182a-4727-b11d-ad0230ea932d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "docs = splitter.split_documents(docs_raw)\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff09121-0899-4973-b478-3c22baa1c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # economical & good quality\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d24147-2ca5-4448-855f-e6f586a7964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f404ab11-b4e6-4842-8794-26492e4e447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741a6262-57e9-4ce3-9026-4975e468d464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. https://www.bbc.com/news/technology\n",
      "An interview between a US journalist and an AI clone of a teenager who was killed during a school shooting has prompted criticism online.\n",
      "\n",
      "\n",
      "\n",
      "Taylor Swift smiling wearing a black beanie hat and black jacket.\n",
      "\n",
      "Elon Musk's AI accused of making explicit AI Taylor Swift videos\n",
      "\n",
      "Grok Imagine's \"spicy\" mod...\n",
      "\n",
      "2. https://www.bbc.com/news/technology\n",
      "Innovation\n",
      "\n",
      "\n",
      "\n",
      "The DeepSeek app from a Chinese AI technology company is displayed on a mobile phone\n",
      "\n",
      "It shocked the market but has China's DeepSeek changed AI?\n",
      "\n",
      "Some six months after DeepSeek shook Silicon Valley, is the Chinese AI chatbot still relevant?\n",
      "\n",
      "2 days ago\n",
      "\n",
      "\n",
      "\n",
      "Dame Stephanie Shirley poses i...\n",
      "\n",
      "3. https://www.bbc.com/news/technology\n",
      "1 Aug 2025\n",
      "\n",
      "Tech Now\n",
      "\n",
      "\n",
      "\n",
      "High-tech tools cracking the case of Chile's lost children\n",
      "\n",
      "High-tech tools cracking the case of Chile's lost children\n",
      "\n",
      "Tech Now visits organisations in Chile using innovative tech to track down missing relatives.\n",
      "\n",
      "25 Jul 2025\n",
      "\n",
      "Tech Now\n",
      "\n",
      "\n",
      "\n",
      "Bringing a baby dinosaur roar to 'li...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the latest AI trends mentioned?\"\n",
    "for i, d in enumerate(vectorstore.similarity_search(query, k=3), 1):\n",
    "    print(f\"{i}. {d.metadata.get('source')}\\n{d.page_content[:300]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249ff77e-ccc5-40e7-9ad7-107b66b49a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.venv/lib/python3.11/site-packages (0.2.12)\n",
      "Requirement already satisfied: langchain-openai in ./.venv/lib/python3.11/site-packages (0.1.7)\n",
      "Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.11/site-packages (1.7.4)\n",
      "Requirement already satisfied: unstructured in ./.venv/lib/python3.11/site-packages (0.18.11)\n",
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: streamlit in ./.venv/lib/python3.11/site-packages (1.48.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.11/site-packages (from langchain) (2.0.42)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.11/site-packages (from langchain) (3.12.15)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in ./.venv/lib/python3.11/site-packages (from langchain) (0.2.36)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.11/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.11/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.11/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.20.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Collecting openai<2.0.0,>=1.24.0 (from langchain-openai)\n",
      "  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.11/site-packages (from tiktoken) (2025.7.34)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: filetype in ./.venv/lib/python3.11/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in ./.venv/lib/python3.11/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.11/site-packages (from unstructured) (6.0.0)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.11/site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.11/site-packages (from unstructured) (4.13.4)\n",
      "Requirement already satisfied: emoji in ./.venv/lib/python3.11/site-packages (from unstructured) (2.14.1)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.11/site-packages (from unstructured) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in ./.venv/lib/python3.11/site-packages (from unstructured) (2025.2.18)\n",
      "Requirement already satisfied: langdetect in ./.venv/lib/python3.11/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in ./.venv/lib/python3.11/site-packages (from unstructured) (3.13.0)\n",
      "Requirement already satisfied: backoff in ./.venv/lib/python3.11/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: unstructured-client in ./.venv/lib/python3.11/site-packages (from unstructured) (0.42.2)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.11/site-packages (from unstructured) (1.17.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from unstructured) (7.0.0)\n",
      "Requirement already satisfied: python-oxmsg in ./.venv/lib/python3.11/site-packages (from unstructured) (0.0.2)\n",
      "Requirement already satisfied: html5lib in ./.venv/lib/python3.11/site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in ./.venv/lib/python3.11/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in ./.venv/lib/python3.11/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in ./.venv/lib/python3.11/site-packages (from streamlit) (6.1.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./.venv/lib/python3.11/site-packages (from streamlit) (8.2.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in ./.venv/lib/python3.11/site-packages (from streamlit) (2.3.1)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in ./.venv/lib/python3.11/site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in ./.venv/lib/python3.11/site-packages (from streamlit) (6.31.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in ./.venv/lib/python3.11/site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in ./.venv/lib/python3.11/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./.venv/lib/python3.11/site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./.venv/lib/python3.11/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in ./.venv/lib/python3.11/site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./.venv/lib/python3.11/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in ./.venv/lib/python3.11/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.11/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.11/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.11/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.11/site-packages (from beautifulsoup4->unstructured) (2.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.1.0)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.11/site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk->unstructured) (1.5.1)\n",
      "Requirement already satisfied: olefile in ./.venv/lib/python3.11/site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured) (45.0.6)\n",
      "Requirement already satisfied: pypdf>=4.0 in ./.venv/lib/python3.11/site-packages (from unstructured-client->unstructured) (5.9.0)\n",
      "Requirement already satisfied: cffi>=1.14 in ./.venv/lib/python3.11/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "Downloading openai-1.99.9-py3-none-any.whl (786 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.1\n",
      "    Uninstalling openai-0.28.1:\n",
      "      Successfully uninstalled openai-0.28.1\n",
      "Successfully installed openai-1.99.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-openai faiss-cpu unstructured tiktoken python-dotenv streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c018c219-5fff-4d8c-986e-ef73fbd8e214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain core\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()  # loads OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f9ae65-760b-4b49-8432-e01a247763f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"/full/path/to/.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e994fd3b-ecba-40c8-9c06-e1236eaa95b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/fariskajani/Code/genai-finance\n",
      "Files here: ['vector_index.pkl', 'sample_text.csv', '.DS_Store', '.env.rtf', 'Untitled.ipynb', '.venv', 'faiss_index', '.ipynb_checkpoints', 'GenAi.ipynb', 'movies.csv', 'nvda_news_1.txt']\n",
      "Env files spotted: ['.env.rtf']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(\"CWD:\", Path().resolve())\n",
    "print(\"Files here:\", [p.name for p in Path().iterdir()])\n",
    "print(\"Env files spotted:\", [p.name for p in Path().glob(\".env*\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08ea523-78b3-4601-b0c4-79c76a28784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/fariskajani/Code/genai-finance\n",
      "Files here: ['vector_index.pkl', 'sample_text.csv', '.DS_Store', '.env.txt', 'Untitled.ipynb', '.venv', 'faiss_index', '.ipynb_checkpoints', 'GenAi.ipynb', 'movies.csv', 'nvda_news_1.txt']\n",
      "Env files spotted: ['.env.txt']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(\"CWD:\", Path().resolve())\n",
    "print(\"Files here:\", [p.name for p in Path().iterdir()])\n",
    "print(\"Env files spotted:\", [p.name for p in Path().glob(\".env*\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "949bd579-36da-4d64-bf35-e60aaa19f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote .env: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ⬅️ put your NEW key here\n",
    "KEY = \"OPENAI_API_KEY\"\n",
    "\n",
    "# write a real .env (no extension)\n",
    "Path(\".env\").write_text(f\"OPENAI_API_KEY={KEY}\\n\")\n",
    "\n",
    "# remove mistaken files if they exist\n",
    "for wrong in [\".env.txt\", \".env.rtf\"]:\n",
    "    try:\n",
    "        Path(wrong).unlink()\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "print(\"Wrote .env:\", Path(\".env\").exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e490d807-8226-4162-b675-321c7d3131fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/fariskajani/Code/genai-finance\n",
      "Key loaded? True\n",
      "sk-pr\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os, pathlib\n",
    "\n",
    "print(\"CWD:\", pathlib.Path().resolve())\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "print(\"Key loaded?\", os.getenv(\"OPENAI_API_KEY\") is not None)\n",
    "print(os.getenv(\"OPENAI_API_KEY\")[:5])  # should print 'sk-'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65046e5-62db-4a25-9662-d6cf552f4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16184eed-2043-45d3-b448-8900ad6c57ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://www.cnbc.com/2024/01/02/stock-market-today.html\",\n",
    "    \"https://www.reuters.com/markets/us/\"\n",
    "]\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b689b49c-3405-4f17-8d43-cc5edfc1835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 2 chunks\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(f\"Split into {len(chunks)} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc895d7a-2f3a-48c1-8147-a97eb90535c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acd778e7-4b8d-4904-b027-f6d755320e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"You are a precise finance analyst. Use the context to answer briefly.\\n\"\n",
    "    \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "570b03d1-ec59-412b-9573-de91df496ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/z9rqrx2562d9qq96khj5vjrc0000gn/T/ipykernel_10628/4105241159.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  result = qa({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " I cannot access the specific article from CNBC, but generally, market sentiment can be influenced by various factors such as economic data releases, corporate earnings reports, geopolitical events, and changes in monetary policy. To assess the current sentiment on US markets, consider recent trends in these areas, investor reactions, and any significant news that may impact market confidence. For the most accurate and up-to-date information, check reliable financial news sources.\n",
      "\n",
      "Sources:\n",
      "- https://www.cnbc.com/2024/01/02/stock-market-today.html\n",
      "- https://www.reuters.com/markets/us/\n"
     ]
    }
   ],
   "source": [
    "query = \"What’s the current sentiment on US markets and why?\"\n",
    "result = qa({\"query\": query})\n",
    "\n",
    "print(\"\\nAnswer:\\n\", result[\"result\"])\n",
    "print(\"\\nSources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(\"-\", doc.metadata.get(\"source\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "388993d6-e794-419a-ab82-6309f1a46bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNumber of chunks:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(docs))\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Inspect a chunk (index 9 just as example)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split docs (you already did this but let's match chunk_overlap=200 for the tutorial)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(docs)  # docs from your URL loader\n",
    "\n",
    "print(\"Number of chunks:\", len(docs))\n",
    "\n",
    "# Inspect a chunk (index 9 just as example)\n",
    "print(docs[9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b11234c-d435-4834-a67d-fc7d3295e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ca8940f-388b-467f-82bc-03f710c52001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectordb = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8c8eac7-5662-4005-b4ff-6b537edd6f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build the FAISS index from your chunks\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# use the same 'docs' (your chunks) and the same embeddings object you created earlier\n",
    "vectordb = FAISS.from_documents(docs, embeddings)   # docs = chunks from the splitter\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee306552-6a30-43d5-89a9-c570c096b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) (Optional) Persist to disk so you can reuse without re-embedding\n",
    "vectordb.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "facc78f3-4d7c-4b24-a3c0-a9ffc4a13531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) (Later) Reload instead of recomputing\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # must match the model used to build it\n",
    "vectordb = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bdf2b6d-0b75-4b7d-a2e1-bd3976d0e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1762c63-4a6d-4833-b3c1-5fc41c4138c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " I don't know.\n",
      "\n",
      "Sources:\n",
      "- https://www.cnbc.com/2024/01/02/stock-market-today.html\n",
      "- https://www.reuters.com/markets/us/\n"
     ]
    }
   ],
   "source": [
    "query = \"What’s the current sentiment on US markets and why?\"\n",
    "result = qa.invoke({\"query\": query})\n",
    "\n",
    "print(\"\\nAnswer:\\n\", result[\"result\"])\n",
    "print(\"\\nSources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(\"-\", doc.metadata.get(\"source\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7eaf2cc-27f4-4476-9626-67894af1e078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What’s the current sentiment on US markets and why?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What’s the current sentiment on US markets and why?\",\n",
      "  \"context\": \"Access Denied\\n\\nYou don't have permission to access \\\"http://www.cnbc.com/2024/01/02/stock-market-today.html\\\" on this server.\\n\\nReference #18.35b01302.1754994108.e3d9bb7\\n\\nhttps://errors.edgesuite.net/18.35b01302.1754994108.e3d9bb7\\n\\nPlease enable JS and disable any ad blocker\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\nAccess Denied\\n\\nYou don't have permission to access \\\"http://www.cnbc.com/2024/01/02/stock-market-today.html\\\" on this server.\\n\\nReference #18.35b01302.1754994108.e3d9bb7\\n\\nhttps://errors.edgesuite.net/18.35b01302.1754994108.e3d9bb7\\n\\nPlease enable JS and disable any ad blocker\\nHuman: What’s the current sentiment on US markets and why?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [1.20s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I don't know.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I don't know.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 4,\n",
      "                \"prompt_tokens\": 148,\n",
      "                \"total_tokens\": 152,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-43e51f36-2c0f-45d2-8334-0d4fb5422b65-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 4,\n",
      "      \"prompt_tokens\": 148,\n",
      "      \"total_tokens\": 152,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [1.21s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"I don't know.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [1.21s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"I don't know.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [1.47s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\n",
      "Answer:\n",
      " I don't know.\n",
      "\n",
      "Sources:\n",
      "- https://www.cnbc.com/2024/01/02/stock-market-today.html\n",
      "- https://www.reuters.com/markets/us/\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.debug = True  # prints retrieval + prompts + LLM call\n",
    "\n",
    "query = \"What’s the current sentiment on US markets and why?\"\n",
    "res = qa.invoke({\"query\": query})  # modern API\n",
    "\n",
    "print(\"\\nAnswer:\\n\", res[\"result\"])\n",
    "print(\"\\nSources:\")\n",
    "for d in res[\"source_documents\"]:\n",
    "    print(\"-\", d.metadata.get(\"source\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1412db7-4e26-4f6e-aa3d-aa6617fc5043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
